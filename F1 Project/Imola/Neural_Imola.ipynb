{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Imola.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nT9UeLbL3tq-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "En25u59w3zlx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "PnL4eIyK317X",
        "outputId": "adf98249-479d-4151-9483-1079ade57359"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-641e61cc-1345-4024-a9cb-32d438810534\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-641e61cc-1345-4024-a9cb-32d438810534\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Imola_GP.csv to Imola_GP.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Imola_GP.csv')"
      ],
      "metadata": {
        "id": "5Gx8y7RL35zB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "9NvWt-ee3-k6",
        "outputId": "b2dd9550-33f3-4d81-ce84-a2bfd2df99ff"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                    Time  DriverNumber                 LapTime  \\\n",
              "0           0  0 days 01:03:54.806000             1                     NaN   \n",
              "1           1  0 days 01:06:20.801000             1  0 days 00:02:25.995000   \n",
              "2           2  0 days 01:08:37.301000             1  0 days 00:02:16.500000   \n",
              "3           3  0 days 01:11:04.728000             1  0 days 00:02:27.427000   \n",
              "4           4  0 days 01:12:36.178000             1  0 days 00:01:31.450000   \n",
              "\n",
              "   LapNumber  Stint              PitOutTime PitInTime             Sector1Time  \\\n",
              "0        1.0    1.0  0 days 00:25:08.250000       NaN                     NaN   \n",
              "1        2.0    1.0                     NaN       NaN  0 days 00:00:54.085000   \n",
              "2        3.0    1.0                     NaN       NaN  0 days 00:00:45.833000   \n",
              "3        4.0    1.0                     NaN       NaN  0 days 00:00:42.546000   \n",
              "4        5.0    1.0                     NaN       NaN  0 days 00:00:29.619000   \n",
              "\n",
              "              Sector2Time  ... SpeedST      Compound TyreLife FreshTyre  \\\n",
              "0  0 days 00:00:31.809000  ...   100.0  INTERMEDIATE      1.0      True   \n",
              "1  0 days 00:00:47.410000  ...   133.0  INTERMEDIATE      2.0      True   \n",
              "2  0 days 00:00:46.168000  ...   164.0  INTERMEDIATE      3.0      True   \n",
              "3  0 days 00:00:48.335000  ...   101.0  INTERMEDIATE      4.0      True   \n",
              "4  0 days 00:00:30.801000  ...   273.0  INTERMEDIATE      5.0      True   \n",
              "\n",
              "             LapStartTime      Team  Driver  TrackStatus IsAccurate  \\\n",
              "0  0 days 01:02:03.225000  Red Bull     VER           24      False   \n",
              "1  0 days 01:03:54.806000  Red Bull     VER            4      False   \n",
              "2  0 days 01:06:20.801000  Red Bull     VER            4      False   \n",
              "3  0 days 01:08:37.301000  Red Bull     VER            4      False   \n",
              "4  0 days 01:11:04.728000  Red Bull     VER            1      False   \n",
              "\n",
              "              LapStartDate  \n",
              "0  2022-04-24 13:03:03.238  \n",
              "1  2022-04-24 13:04:54.819  \n",
              "2  2022-04-24 13:07:20.814  \n",
              "3  2022-04-24 13:09:37.314  \n",
              "4  2022-04-24 13:12:04.741  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3419c7c1-49fc-4982-88ec-b14e28848ba6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Time</th>\n",
              "      <th>DriverNumber</th>\n",
              "      <th>LapTime</th>\n",
              "      <th>LapNumber</th>\n",
              "      <th>Stint</th>\n",
              "      <th>PitOutTime</th>\n",
              "      <th>PitInTime</th>\n",
              "      <th>Sector1Time</th>\n",
              "      <th>Sector2Time</th>\n",
              "      <th>...</th>\n",
              "      <th>SpeedST</th>\n",
              "      <th>Compound</th>\n",
              "      <th>TyreLife</th>\n",
              "      <th>FreshTyre</th>\n",
              "      <th>LapStartTime</th>\n",
              "      <th>Team</th>\n",
              "      <th>Driver</th>\n",
              "      <th>TrackStatus</th>\n",
              "      <th>IsAccurate</th>\n",
              "      <th>LapStartDate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0 days 01:03:54.806000</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0 days 00:25:08.250000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0 days 00:00:31.809000</td>\n",
              "      <td>...</td>\n",
              "      <td>100.0</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0 days 01:02:03.225000</td>\n",
              "      <td>Red Bull</td>\n",
              "      <td>VER</td>\n",
              "      <td>24</td>\n",
              "      <td>False</td>\n",
              "      <td>2022-04-24 13:03:03.238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0 days 01:06:20.801000</td>\n",
              "      <td>1</td>\n",
              "      <td>0 days 00:02:25.995000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0 days 00:00:54.085000</td>\n",
              "      <td>0 days 00:00:47.410000</td>\n",
              "      <td>...</td>\n",
              "      <td>133.0</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>2.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0 days 01:03:54.806000</td>\n",
              "      <td>Red Bull</td>\n",
              "      <td>VER</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>2022-04-24 13:04:54.819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0 days 01:08:37.301000</td>\n",
              "      <td>1</td>\n",
              "      <td>0 days 00:02:16.500000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0 days 00:00:45.833000</td>\n",
              "      <td>0 days 00:00:46.168000</td>\n",
              "      <td>...</td>\n",
              "      <td>164.0</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>3.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0 days 01:06:20.801000</td>\n",
              "      <td>Red Bull</td>\n",
              "      <td>VER</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>2022-04-24 13:07:20.814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0 days 01:11:04.728000</td>\n",
              "      <td>1</td>\n",
              "      <td>0 days 00:02:27.427000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0 days 00:00:42.546000</td>\n",
              "      <td>0 days 00:00:48.335000</td>\n",
              "      <td>...</td>\n",
              "      <td>101.0</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>4.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0 days 01:08:37.301000</td>\n",
              "      <td>Red Bull</td>\n",
              "      <td>VER</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>2022-04-24 13:09:37.314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0 days 01:12:36.178000</td>\n",
              "      <td>1</td>\n",
              "      <td>0 days 00:01:31.450000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0 days 00:00:29.619000</td>\n",
              "      <td>0 days 00:00:30.801000</td>\n",
              "      <td>...</td>\n",
              "      <td>273.0</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0 days 01:11:04.728000</td>\n",
              "      <td>Red Bull</td>\n",
              "      <td>VER</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>2022-04-24 13:12:04.741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3419c7c1-49fc-4982-88ec-b14e28848ba6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3419c7c1-49fc-4982-88ec-b14e28848ba6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3419c7c1-49fc-4982-88ec-b14e28848ba6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import f1_preprocessor\n",
        "from f1_preprocessor import cleaning"
      ],
      "metadata": {
        "id": "CjhDhGdt3_AF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = cleaning(df)"
      ],
      "metadata": {
        "id": "3jbdIDwl4aKv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.pivot_table(index = 'PitInTime', aggfunc = 'size').plot(kind='bar',title='Label Imbalances')\n",
        "plt.savefig('imola_label_imbalance.png',dpi = 1200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "a09hcZtM4b63",
        "outputId": "2c68cfd6-d099-4c87-ce8c-eecb219c2eb6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHhsWd3S6GnJ",
        "outputId": "090777b3-c4e1-4219-fd2d-694b3226cf42"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1104 entries, 1 to 1131\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   LapTime      1104 non-null   float64\n",
            " 1   LapNumber    1104 non-null   float64\n",
            " 2   Stint        1104 non-null   float64\n",
            " 3   PitOutTime   1104 non-null   object \n",
            " 4   PitInTime    1104 non-null   object \n",
            " 5   Sector1Time  1104 non-null   float64\n",
            " 6   Sector2Time  1104 non-null   float64\n",
            " 7   Sector3Time  1104 non-null   float64\n",
            " 8   Compound     1104 non-null   int64  \n",
            " 9   TyreLife     1104 non-null   float64\n",
            " 10  Team         1104 non-null   object \n",
            " 11  Driver       1104 non-null   object \n",
            "dtypes: float64(7), int64(1), object(4)\n",
            "memory usage: 112.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.astype({'PitInTime':int}, errors = 'raise')\n",
        "df = df.astype({'PitOutTime': int}, errors = 'raise')"
      ],
      "metadata": {
        "id": "rA7GZXDF6lan"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LEHa_gs7WZs",
        "outputId": "6f03ad32-a415-4e6b-b265-54a14664d5fd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1104 entries, 1 to 1131\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   LapTime      1104 non-null   float64\n",
            " 1   LapNumber    1104 non-null   float64\n",
            " 2   Stint        1104 non-null   float64\n",
            " 3   PitOutTime   1104 non-null   int64  \n",
            " 4   PitInTime    1104 non-null   int64  \n",
            " 5   Sector1Time  1104 non-null   float64\n",
            " 6   Sector2Time  1104 non-null   float64\n",
            " 7   Sector3Time  1104 non-null   float64\n",
            " 8   Compound     1104 non-null   int64  \n",
            " 9   TyreLife     1104 non-null   float64\n",
            " 10  Team         1104 non-null   object \n",
            " 11  Driver       1104 non-null   object \n",
            "dtypes: float64(7), int64(3), object(2)\n",
            "memory usage: 112.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Team','Driver','Sector3Time'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "R3aqQbVX8S6Z"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USING SMOTE TO POPULATE IMBALANCED DATASET"
      ],
      "metadata": {
        "id": "N02eOtgi7XIg"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "Wd_zPVU17z1o"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop(['LapTime'],axis=1)\n",
        "y = df['LapTime']"
      ],
      "metadata": {
        "id": "D-8e-eIC71_V"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_resampled, y_resampled = SMOTE().fit_resample(df[['LapNumber', 'Stint', 'Sector1Time', 'Sector2Time', 'Compound','TyreLife']],df['PitInTime'])"
      ],
      "metadata": {
        "id": "d0hQNp3M8mi5"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(y_resampled).value_counts().plot(kind='bar',title='Class Distibution after applying SMOTE',xlabel='Pitstop')\n",
        "plt.savefig('imola_label_balanced.png',dpi = 1200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "X1FvNJfH8yVs",
        "outputId": "99dc886b-5624-41cb-8f41-7b88c864864b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ljSUxZzR9hsp"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=101)"
      ],
      "metadata": {
        "id": "Q-PLqH7H9y6Y"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "zTxhZBfc97_S"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "241-Pckx9_zZ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = scaler.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "EFsobexE-BDj"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "QpQLQtye-DHl"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "M3CXSc5d-FNL"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense,Dropout"
      ],
      "metadata": {
        "id": "_t276utY-HxJ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgMp8U0S-Ka6",
        "outputId": "b08e5f5d-ad9e-4dc5-b8f6-2a4d21b537f4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1510, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(6,activation='relu'))\n",
        "model.add(Dense(6,activation='relu'))\n",
        "model.add(Dense(3,activation='relu'))\n",
        "\n",
        "# BINARY CLASSIFICATION\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "XAgQmNBc-MAE"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "9kfj_Wmh_lrw"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=50)"
      ],
      "metadata": {
        "id": "r5R6etu5_yLE"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train,y=y_train,epochs=2000,validation_data=(X_test,y_test),callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs-npxZp-r9N",
        "outputId": "77d77364-1f12-4724-8bfc-3332ef870932"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "48/48 [==============================] - 1s 6ms/step - loss: 0.6949 - val_loss: 0.6849\n",
            "Epoch 2/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6799 - val_loss: 0.6758\n",
            "Epoch 3/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6639 - val_loss: 0.6511\n",
            "Epoch 4/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6374 - val_loss: 0.6280\n",
            "Epoch 5/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6161 - val_loss: 0.6102\n",
            "Epoch 6/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5987 - val_loss: 0.5963\n",
            "Epoch 7/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.5850\n",
            "Epoch 8/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5729 - val_loss: 0.5739\n",
            "Epoch 9/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5619 - val_loss: 0.5646\n",
            "Epoch 10/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5509 - val_loss: 0.5535\n",
            "Epoch 11/2000\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5411 - val_loss: 0.5434\n",
            "Epoch 12/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5288 - val_loss: 0.5340\n",
            "Epoch 13/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5189 - val_loss: 0.5268\n",
            "Epoch 14/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5092 - val_loss: 0.5159\n",
            "Epoch 15/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5006 - val_loss: 0.5072\n",
            "Epoch 16/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4910 - val_loss: 0.4989\n",
            "Epoch 17/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4825 - val_loss: 0.4916\n",
            "Epoch 18/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4755 - val_loss: 0.4841\n",
            "Epoch 19/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 0.4770\n",
            "Epoch 20/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.4751\n",
            "Epoch 21/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.4659\n",
            "Epoch 22/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4461 - val_loss: 0.4618\n",
            "Epoch 23/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4410 - val_loss: 0.4560\n",
            "Epoch 24/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4341 - val_loss: 0.4487\n",
            "Epoch 25/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4278 - val_loss: 0.4494\n",
            "Epoch 26/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.4229 - val_loss: 0.4400\n",
            "Epoch 27/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4181 - val_loss: 0.4346\n",
            "Epoch 28/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4140 - val_loss: 0.4333\n",
            "Epoch 29/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4094 - val_loss: 0.4271\n",
            "Epoch 30/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4037 - val_loss: 0.4235\n",
            "Epoch 31/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.4213\n",
            "Epoch 32/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 0.4199\n",
            "Epoch 33/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3940 - val_loss: 0.4151\n",
            "Epoch 34/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3901 - val_loss: 0.4101\n",
            "Epoch 35/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3863 - val_loss: 0.4062\n",
            "Epoch 36/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3826 - val_loss: 0.4042\n",
            "Epoch 37/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.4012\n",
            "Epoch 38/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3778 - val_loss: 0.3992\n",
            "Epoch 39/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3742 - val_loss: 0.3978\n",
            "Epoch 40/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3712 - val_loss: 0.3941\n",
            "Epoch 41/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3702 - val_loss: 0.3929\n",
            "Epoch 42/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3675 - val_loss: 0.3883\n",
            "Epoch 43/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3661 - val_loss: 0.3865\n",
            "Epoch 44/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3634 - val_loss: 0.3858\n",
            "Epoch 45/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3617 - val_loss: 0.3833\n",
            "Epoch 46/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3583 - val_loss: 0.3808\n",
            "Epoch 47/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3566 - val_loss: 0.3814\n",
            "Epoch 48/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3555 - val_loss: 0.3772\n",
            "Epoch 49/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3525 - val_loss: 0.3743\n",
            "Epoch 50/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3508 - val_loss: 0.3734\n",
            "Epoch 51/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3493 - val_loss: 0.3719\n",
            "Epoch 52/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3484 - val_loss: 0.3700\n",
            "Epoch 53/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3681\n",
            "Epoch 54/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3742\n",
            "Epoch 55/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 0.3658\n",
            "Epoch 56/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.3639\n",
            "Epoch 57/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3399 - val_loss: 0.3643\n",
            "Epoch 58/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3399 - val_loss: 0.3614\n",
            "Epoch 59/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3386 - val_loss: 0.3597\n",
            "Epoch 60/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3359 - val_loss: 0.3582\n",
            "Epoch 61/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3353 - val_loss: 0.3572\n",
            "Epoch 62/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3561\n",
            "Epoch 63/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.3547\n",
            "Epoch 64/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3320 - val_loss: 0.3550\n",
            "Epoch 65/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3311 - val_loss: 0.3526\n",
            "Epoch 66/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.3509\n",
            "Epoch 67/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3279 - val_loss: 0.3524\n",
            "Epoch 68/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.3508\n",
            "Epoch 69/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3274 - val_loss: 0.3489\n",
            "Epoch 70/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3248 - val_loss: 0.3477\n",
            "Epoch 71/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3237 - val_loss: 0.3480\n",
            "Epoch 72/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3233 - val_loss: 0.3452\n",
            "Epoch 73/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3215 - val_loss: 0.3458\n",
            "Epoch 74/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3203 - val_loss: 0.3437\n",
            "Epoch 75/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3200 - val_loss: 0.3459\n",
            "Epoch 76/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3189 - val_loss: 0.3424\n",
            "Epoch 77/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3179 - val_loss: 0.3442\n",
            "Epoch 78/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3219 - val_loss: 0.3456\n",
            "Epoch 79/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3156 - val_loss: 0.3392\n",
            "Epoch 80/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3161 - val_loss: 0.3394\n",
            "Epoch 81/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3149 - val_loss: 0.3380\n",
            "Epoch 82/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.3374\n",
            "Epoch 83/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3129 - val_loss: 0.3369\n",
            "Epoch 84/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.3384\n",
            "Epoch 85/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3136 - val_loss: 0.3378\n",
            "Epoch 86/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3117 - val_loss: 0.3368\n",
            "Epoch 87/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3123 - val_loss: 0.3333\n",
            "Epoch 88/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3097 - val_loss: 0.3330\n",
            "Epoch 89/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3092 - val_loss: 0.3336\n",
            "Epoch 90/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3078 - val_loss: 0.3313\n",
            "Epoch 91/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3084 - val_loss: 0.3309\n",
            "Epoch 92/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3091 - val_loss: 0.3337\n",
            "Epoch 93/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3057 - val_loss: 0.3309\n",
            "Epoch 94/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3062 - val_loss: 0.3327\n",
            "Epoch 95/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3041 - val_loss: 0.3279\n",
            "Epoch 96/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3057 - val_loss: 0.3282\n",
            "Epoch 97/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3040 - val_loss: 0.3275\n",
            "Epoch 98/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3026 - val_loss: 0.3270\n",
            "Epoch 99/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3038 - val_loss: 0.3286\n",
            "Epoch 100/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3017 - val_loss: 0.3287\n",
            "Epoch 101/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3033 - val_loss: 0.3241\n",
            "Epoch 102/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3238\n",
            "Epoch 103/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3245\n",
            "Epoch 104/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2997 - val_loss: 0.3229\n",
            "Epoch 105/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3211\n",
            "Epoch 106/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2994 - val_loss: 0.3204\n",
            "Epoch 107/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2981 - val_loss: 0.3216\n",
            "Epoch 108/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2984 - val_loss: 0.3197\n",
            "Epoch 109/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2960 - val_loss: 0.3189\n",
            "Epoch 110/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2953 - val_loss: 0.3186\n",
            "Epoch 111/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2943 - val_loss: 0.3190\n",
            "Epoch 112/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2954 - val_loss: 0.3181\n",
            "Epoch 113/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2947 - val_loss: 0.3167\n",
            "Epoch 114/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2942 - val_loss: 0.3157\n",
            "Epoch 115/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2928 - val_loss: 0.3156\n",
            "Epoch 116/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2918 - val_loss: 0.3148\n",
            "Epoch 117/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2921 - val_loss: 0.3207\n",
            "Epoch 118/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2911 - val_loss: 0.3173\n",
            "Epoch 119/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2916 - val_loss: 0.3128\n",
            "Epoch 120/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2909 - val_loss: 0.3145\n",
            "Epoch 121/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2878 - val_loss: 0.3118\n",
            "Epoch 122/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2890 - val_loss: 0.3129\n",
            "Epoch 123/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2874 - val_loss: 0.3131\n",
            "Epoch 124/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2882 - val_loss: 0.3135\n",
            "Epoch 125/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2870 - val_loss: 0.3136\n",
            "Epoch 126/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2888 - val_loss: 0.3098\n",
            "Epoch 127/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2863 - val_loss: 0.3106\n",
            "Epoch 128/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2865 - val_loss: 0.3076\n",
            "Epoch 129/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2858 - val_loss: 0.3082\n",
            "Epoch 130/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2830 - val_loss: 0.3070\n",
            "Epoch 131/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2858 - val_loss: 0.3097\n",
            "Epoch 132/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2829 - val_loss: 0.3047\n",
            "Epoch 133/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2824 - val_loss: 0.3058\n",
            "Epoch 134/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2817 - val_loss: 0.3035\n",
            "Epoch 135/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2791 - val_loss: 0.3049\n",
            "Epoch 136/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2790 - val_loss: 0.3070\n",
            "Epoch 137/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2797 - val_loss: 0.3036\n",
            "Epoch 138/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2805 - val_loss: 0.3018\n",
            "Epoch 139/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2779 - val_loss: 0.3013\n",
            "Epoch 140/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2773 - val_loss: 0.3019\n",
            "Epoch 141/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2773 - val_loss: 0.2994\n",
            "Epoch 142/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2757 - val_loss: 0.2992\n",
            "Epoch 143/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2768 - val_loss: 0.2976\n",
            "Epoch 144/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2758 - val_loss: 0.2966\n",
            "Epoch 145/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2732 - val_loss: 0.2958\n",
            "Epoch 146/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2740 - val_loss: 0.2968\n",
            "Epoch 147/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2716 - val_loss: 0.3018\n",
            "Epoch 148/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2738 - val_loss: 0.2941\n",
            "Epoch 149/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2715 - val_loss: 0.2927\n",
            "Epoch 150/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2706 - val_loss: 0.2912\n",
            "Epoch 151/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2683 - val_loss: 0.2906\n",
            "Epoch 152/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2694 - val_loss: 0.2886\n",
            "Epoch 153/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2694 - val_loss: 0.2932\n",
            "Epoch 154/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2675 - val_loss: 0.2888\n",
            "Epoch 155/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2663 - val_loss: 0.2879\n",
            "Epoch 156/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2639 - val_loss: 0.2908\n",
            "Epoch 157/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2657 - val_loss: 0.2849\n",
            "Epoch 158/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2615 - val_loss: 0.2885\n",
            "Epoch 159/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2624 - val_loss: 0.2824\n",
            "Epoch 160/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2591 - val_loss: 0.2853\n",
            "Epoch 161/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2572 - val_loss: 0.2825\n",
            "Epoch 162/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2586 - val_loss: 0.2887\n",
            "Epoch 163/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2560 - val_loss: 0.2860\n",
            "Epoch 164/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2537 - val_loss: 0.2790\n",
            "Epoch 165/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2539 - val_loss: 0.2783\n",
            "Epoch 166/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2536 - val_loss: 0.2782\n",
            "Epoch 167/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2527 - val_loss: 0.2793\n",
            "Epoch 168/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2541 - val_loss: 0.2783\n",
            "Epoch 169/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2501 - val_loss: 0.2749\n",
            "Epoch 170/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2502 - val_loss: 0.2744\n",
            "Epoch 171/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2492 - val_loss: 0.2745\n",
            "Epoch 172/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2515 - val_loss: 0.2777\n",
            "Epoch 173/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2503 - val_loss: 0.2727\n",
            "Epoch 174/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2487 - val_loss: 0.2716\n",
            "Epoch 175/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2466 - val_loss: 0.2749\n",
            "Epoch 176/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2476 - val_loss: 0.2716\n",
            "Epoch 177/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2459 - val_loss: 0.2719\n",
            "Epoch 178/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2454 - val_loss: 0.2729\n",
            "Epoch 179/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2463 - val_loss: 0.2693\n",
            "Epoch 180/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2498 - val_loss: 0.2716\n",
            "Epoch 181/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2450 - val_loss: 0.2692\n",
            "Epoch 182/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2433 - val_loss: 0.2694\n",
            "Epoch 183/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2438 - val_loss: 0.2660\n",
            "Epoch 184/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2432 - val_loss: 0.2689\n",
            "Epoch 185/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.2664\n",
            "Epoch 186/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2438 - val_loss: 0.2651\n",
            "Epoch 187/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2412 - val_loss: 0.2681\n",
            "Epoch 188/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2411 - val_loss: 0.2673\n",
            "Epoch 189/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2382 - val_loss: 0.2647\n",
            "Epoch 190/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2381 - val_loss: 0.2639\n",
            "Epoch 191/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2381 - val_loss: 0.2622\n",
            "Epoch 192/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2383 - val_loss: 0.2625\n",
            "Epoch 193/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2375 - val_loss: 0.2656\n",
            "Epoch 194/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2423 - val_loss: 0.2629\n",
            "Epoch 195/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2379 - val_loss: 0.2604\n",
            "Epoch 196/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2363 - val_loss: 0.2600\n",
            "Epoch 197/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2364 - val_loss: 0.2605\n",
            "Epoch 198/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2370 - val_loss: 0.2615\n",
            "Epoch 199/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2365 - val_loss: 0.2579\n",
            "Epoch 200/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2355 - val_loss: 0.2596\n",
            "Epoch 201/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2336 - val_loss: 0.2606\n",
            "Epoch 202/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2348 - val_loss: 0.2639\n",
            "Epoch 203/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2352 - val_loss: 0.2639\n",
            "Epoch 204/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2424 - val_loss: 0.2557\n",
            "Epoch 205/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2335 - val_loss: 0.2588\n",
            "Epoch 206/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2323 - val_loss: 0.2588\n",
            "Epoch 207/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2325 - val_loss: 0.2577\n",
            "Epoch 208/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2318 - val_loss: 0.2544\n",
            "Epoch 209/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2331 - val_loss: 0.2574\n",
            "Epoch 210/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2310 - val_loss: 0.2553\n",
            "Epoch 211/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2311 - val_loss: 0.2559\n",
            "Epoch 212/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2328 - val_loss: 0.2545\n",
            "Epoch 213/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2289 - val_loss: 0.2547\n",
            "Epoch 214/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2273 - val_loss: 0.2593\n",
            "Epoch 215/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2322 - val_loss: 0.2544\n",
            "Epoch 216/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2285 - val_loss: 0.2549\n",
            "Epoch 217/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2284 - val_loss: 0.2499\n",
            "Epoch 218/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2286 - val_loss: 0.2522\n",
            "Epoch 219/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2271 - val_loss: 0.2528\n",
            "Epoch 220/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2288 - val_loss: 0.2565\n",
            "Epoch 221/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2271 - val_loss: 0.2506\n",
            "Epoch 222/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2270 - val_loss: 0.2524\n",
            "Epoch 223/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2266 - val_loss: 0.2526\n",
            "Epoch 224/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2275 - val_loss: 0.2527\n",
            "Epoch 225/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2302 - val_loss: 0.2476\n",
            "Epoch 226/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2241 - val_loss: 0.2564\n",
            "Epoch 227/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2258 - val_loss: 0.2493\n",
            "Epoch 228/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2255 - val_loss: 0.2484\n",
            "Epoch 229/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2246 - val_loss: 0.2498\n",
            "Epoch 230/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2244 - val_loss: 0.2490\n",
            "Epoch 231/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2243 - val_loss: 0.2494\n",
            "Epoch 232/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2284 - val_loss: 0.2469\n",
            "Epoch 233/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2276 - val_loss: 0.2490\n",
            "Epoch 234/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2248 - val_loss: 0.2474\n",
            "Epoch 235/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2247 - val_loss: 0.2473\n",
            "Epoch 236/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2240 - val_loss: 0.2485\n",
            "Epoch 237/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2239 - val_loss: 0.2466\n",
            "Epoch 238/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2232 - val_loss: 0.2461\n",
            "Epoch 239/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2263 - val_loss: 0.2480\n",
            "Epoch 240/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2223 - val_loss: 0.2493\n",
            "Epoch 241/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2220 - val_loss: 0.2530\n",
            "Epoch 242/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2278 - val_loss: 0.2544\n",
            "Epoch 243/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2269 - val_loss: 0.2513\n",
            "Epoch 244/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2224 - val_loss: 0.2511\n",
            "Epoch 245/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2231 - val_loss: 0.2463\n",
            "Epoch 246/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2225 - val_loss: 0.2486\n",
            "Epoch 247/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2234 - val_loss: 0.2449\n",
            "Epoch 248/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2228 - val_loss: 0.2467\n",
            "Epoch 249/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2181 - val_loss: 0.2472\n",
            "Epoch 250/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2246 - val_loss: 0.2462\n",
            "Epoch 251/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2193 - val_loss: 0.2484\n",
            "Epoch 252/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2188 - val_loss: 0.2471\n",
            "Epoch 253/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2239 - val_loss: 0.2439\n",
            "Epoch 254/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2188 - val_loss: 0.2439\n",
            "Epoch 255/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2210 - val_loss: 0.2440\n",
            "Epoch 256/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2194 - val_loss: 0.2441\n",
            "Epoch 257/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2208 - val_loss: 0.2428\n",
            "Epoch 258/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2190 - val_loss: 0.2449\n",
            "Epoch 259/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2203 - val_loss: 0.2448\n",
            "Epoch 260/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2169 - val_loss: 0.2433\n",
            "Epoch 261/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2183 - val_loss: 0.2447\n",
            "Epoch 262/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2180 - val_loss: 0.2455\n",
            "Epoch 263/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2191 - val_loss: 0.2445\n",
            "Epoch 264/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2181 - val_loss: 0.2458\n",
            "Epoch 265/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2196 - val_loss: 0.2439\n",
            "Epoch 266/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2167 - val_loss: 0.2466\n",
            "Epoch 267/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2174 - val_loss: 0.2478\n",
            "Epoch 268/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2166 - val_loss: 0.2418\n",
            "Epoch 269/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2170 - val_loss: 0.2402\n",
            "Epoch 270/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2168 - val_loss: 0.2439\n",
            "Epoch 271/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2160 - val_loss: 0.2440\n",
            "Epoch 272/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2146 - val_loss: 0.2401\n",
            "Epoch 273/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2148 - val_loss: 0.2417\n",
            "Epoch 274/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2143 - val_loss: 0.2408\n",
            "Epoch 275/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2171 - val_loss: 0.2428\n",
            "Epoch 276/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2146 - val_loss: 0.2418\n",
            "Epoch 277/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2157 - val_loss: 0.2411\n",
            "Epoch 278/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2141 - val_loss: 0.2391\n",
            "Epoch 279/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2132 - val_loss: 0.2416\n",
            "Epoch 280/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2172 - val_loss: 0.2407\n",
            "Epoch 281/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2134 - val_loss: 0.2390\n",
            "Epoch 282/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2126 - val_loss: 0.2406\n",
            "Epoch 283/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2151 - val_loss: 0.2392\n",
            "Epoch 284/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2124 - val_loss: 0.2411\n",
            "Epoch 285/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2120 - val_loss: 0.2472\n",
            "Epoch 286/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.2425\n",
            "Epoch 287/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2164 - val_loss: 0.2362\n",
            "Epoch 288/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2177 - val_loss: 0.2373\n",
            "Epoch 289/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2143 - val_loss: 0.2427\n",
            "Epoch 290/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2128 - val_loss: 0.2397\n",
            "Epoch 291/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2185 - val_loss: 0.2419\n",
            "Epoch 292/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2137 - val_loss: 0.2383\n",
            "Epoch 293/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2129 - val_loss: 0.2383\n",
            "Epoch 294/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2116 - val_loss: 0.2361\n",
            "Epoch 295/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2117 - val_loss: 0.2387\n",
            "Epoch 296/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2116 - val_loss: 0.2396\n",
            "Epoch 297/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2127 - val_loss: 0.2425\n",
            "Epoch 298/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2128 - val_loss: 0.2393\n",
            "Epoch 299/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2129 - val_loss: 0.2381\n",
            "Epoch 300/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2108 - val_loss: 0.2456\n",
            "Epoch 301/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2121 - val_loss: 0.2411\n",
            "Epoch 302/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2122 - val_loss: 0.2389\n",
            "Epoch 303/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2109 - val_loss: 0.2383\n",
            "Epoch 304/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2137 - val_loss: 0.2363\n",
            "Epoch 305/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2104 - val_loss: 0.2378\n",
            "Epoch 306/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2109 - val_loss: 0.2374\n",
            "Epoch 307/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2105 - val_loss: 0.2347\n",
            "Epoch 308/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2098 - val_loss: 0.2546\n",
            "Epoch 309/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2153 - val_loss: 0.2410\n",
            "Epoch 310/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2127 - val_loss: 0.2405\n",
            "Epoch 311/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2094 - val_loss: 0.2348\n",
            "Epoch 312/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2088 - val_loss: 0.2360\n",
            "Epoch 313/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2094 - val_loss: 0.2350\n",
            "Epoch 314/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2069 - val_loss: 0.2353\n",
            "Epoch 315/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2133 - val_loss: 0.2364\n",
            "Epoch 316/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2095 - val_loss: 0.2363\n",
            "Epoch 317/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2109 - val_loss: 0.2386\n",
            "Epoch 318/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2105 - val_loss: 0.2355\n",
            "Epoch 319/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2108 - val_loss: 0.2345\n",
            "Epoch 320/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2081 - val_loss: 0.2394\n",
            "Epoch 321/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2169 - val_loss: 0.2349\n",
            "Epoch 322/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2090 - val_loss: 0.2334\n",
            "Epoch 323/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2095 - val_loss: 0.2342\n",
            "Epoch 324/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2071 - val_loss: 0.2343\n",
            "Epoch 325/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2075 - val_loss: 0.2330\n",
            "Epoch 326/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2089 - val_loss: 0.2333\n",
            "Epoch 327/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2108 - val_loss: 0.2300\n",
            "Epoch 328/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2094 - val_loss: 0.2350\n",
            "Epoch 329/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2082 - val_loss: 0.2331\n",
            "Epoch 330/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2084 - val_loss: 0.2330\n",
            "Epoch 331/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2095 - val_loss: 0.2337\n",
            "Epoch 332/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2074 - val_loss: 0.2446\n",
            "Epoch 333/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2092 - val_loss: 0.2368\n",
            "Epoch 334/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2053 - val_loss: 0.2328\n",
            "Epoch 335/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2043 - val_loss: 0.2312\n",
            "Epoch 336/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2080 - val_loss: 0.2312\n",
            "Epoch 337/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2058 - val_loss: 0.2316\n",
            "Epoch 338/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2046 - val_loss: 0.2328\n",
            "Epoch 339/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2063 - val_loss: 0.2339\n",
            "Epoch 340/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2068 - val_loss: 0.2370\n",
            "Epoch 341/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2055 - val_loss: 0.2326\n",
            "Epoch 342/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2086 - val_loss: 0.2296\n",
            "Epoch 343/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2065 - val_loss: 0.2409\n",
            "Epoch 344/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2074 - val_loss: 0.2306\n",
            "Epoch 345/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2046 - val_loss: 0.2374\n",
            "Epoch 346/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2080 - val_loss: 0.2340\n",
            "Epoch 347/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2055 - val_loss: 0.2330\n",
            "Epoch 348/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2083 - val_loss: 0.2331\n",
            "Epoch 349/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2059 - val_loss: 0.2337\n",
            "Epoch 350/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2078 - val_loss: 0.2309\n",
            "Epoch 351/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2055 - val_loss: 0.2311\n",
            "Epoch 352/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2041 - val_loss: 0.2316\n",
            "Epoch 353/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2068 - val_loss: 0.2373\n",
            "Epoch 354/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2075 - val_loss: 0.2302\n",
            "Epoch 355/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2044 - val_loss: 0.2301\n",
            "Epoch 356/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2032 - val_loss: 0.2300\n",
            "Epoch 357/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2072 - val_loss: 0.2329\n",
            "Epoch 358/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2031 - val_loss: 0.2361\n",
            "Epoch 359/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2070 - val_loss: 0.2329\n",
            "Epoch 360/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2041 - val_loss: 0.2284\n",
            "Epoch 361/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2047 - val_loss: 0.2296\n",
            "Epoch 362/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2073 - val_loss: 0.2278\n",
            "Epoch 363/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2047 - val_loss: 0.2299\n",
            "Epoch 364/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2022 - val_loss: 0.2394\n",
            "Epoch 365/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2027 - val_loss: 0.2324\n",
            "Epoch 366/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2020 - val_loss: 0.2287\n",
            "Epoch 367/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2062 - val_loss: 0.2304\n",
            "Epoch 368/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2039 - val_loss: 0.2336\n",
            "Epoch 369/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2056 - val_loss: 0.2284\n",
            "Epoch 370/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2040 - val_loss: 0.2322\n",
            "Epoch 371/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2342\n",
            "Epoch 372/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2038 - val_loss: 0.2292\n",
            "Epoch 373/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2053 - val_loss: 0.2331\n",
            "Epoch 374/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2016 - val_loss: 0.2285\n",
            "Epoch 375/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2037 - val_loss: 0.2382\n",
            "Epoch 376/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2053 - val_loss: 0.2305\n",
            "Epoch 377/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2022 - val_loss: 0.2311\n",
            "Epoch 378/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2020 - val_loss: 0.2328\n",
            "Epoch 379/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2021 - val_loss: 0.2263\n",
            "Epoch 380/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2046 - val_loss: 0.2318\n",
            "Epoch 381/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2017 - val_loss: 0.2279\n",
            "Epoch 382/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2047 - val_loss: 0.2429\n",
            "Epoch 383/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2010 - val_loss: 0.2317\n",
            "Epoch 384/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2010 - val_loss: 0.2275\n",
            "Epoch 385/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2023 - val_loss: 0.2293\n",
            "Epoch 386/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2031 - val_loss: 0.2327\n",
            "Epoch 387/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2023 - val_loss: 0.2291\n",
            "Epoch 388/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2049 - val_loss: 0.2362\n",
            "Epoch 389/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2042 - val_loss: 0.2293\n",
            "Epoch 390/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2019 - val_loss: 0.2332\n",
            "Epoch 391/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2105 - val_loss: 0.2275\n",
            "Epoch 392/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2000 - val_loss: 0.2283\n",
            "Epoch 393/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2060 - val_loss: 0.2305\n",
            "Epoch 394/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2078 - val_loss: 0.2274\n",
            "Epoch 395/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2003 - val_loss: 0.2276\n",
            "Epoch 396/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2026 - val_loss: 0.2268\n",
            "Epoch 397/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1978 - val_loss: 0.2255\n",
            "Epoch 398/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1975 - val_loss: 0.2385\n",
            "Epoch 399/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2000 - val_loss: 0.2311\n",
            "Epoch 400/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2038 - val_loss: 0.2289\n",
            "Epoch 401/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1988 - val_loss: 0.2280\n",
            "Epoch 402/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2398\n",
            "Epoch 403/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2037 - val_loss: 0.2311\n",
            "Epoch 404/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2002 - val_loss: 0.2275\n",
            "Epoch 405/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1997 - val_loss: 0.2263\n",
            "Epoch 406/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2031 - val_loss: 0.2257\n",
            "Epoch 407/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1995 - val_loss: 0.2300\n",
            "Epoch 408/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2025 - val_loss: 0.2269\n",
            "Epoch 409/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2014 - val_loss: 0.2280\n",
            "Epoch 410/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1984 - val_loss: 0.2363\n",
            "Epoch 411/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2000 - val_loss: 0.2284\n",
            "Epoch 412/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2005 - val_loss: 0.2273\n",
            "Epoch 413/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2014 - val_loss: 0.2267\n",
            "Epoch 414/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2005 - val_loss: 0.2287\n",
            "Epoch 415/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1995 - val_loss: 0.2271\n",
            "Epoch 416/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2004 - val_loss: 0.2294\n",
            "Epoch 417/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1990 - val_loss: 0.2331\n",
            "Epoch 418/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2061 - val_loss: 0.2331\n",
            "Epoch 419/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2106 - val_loss: 0.2285\n",
            "Epoch 420/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1988 - val_loss: 0.2260\n",
            "Epoch 421/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1978 - val_loss: 0.2259\n",
            "Epoch 422/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1981 - val_loss: 0.2250\n",
            "Epoch 423/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1971 - val_loss: 0.2255\n",
            "Epoch 424/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1953 - val_loss: 0.2332\n",
            "Epoch 425/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1999 - val_loss: 0.2262\n",
            "Epoch 426/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2029 - val_loss: 0.2261\n",
            "Epoch 427/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2046 - val_loss: 0.2335\n",
            "Epoch 428/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1986 - val_loss: 0.2261\n",
            "Epoch 429/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1954 - val_loss: 0.2274\n",
            "Epoch 430/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2016 - val_loss: 0.2235\n",
            "Epoch 431/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2003 - val_loss: 0.2236\n",
            "Epoch 432/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1957 - val_loss: 0.2238\n",
            "Epoch 433/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1991 - val_loss: 0.2273\n",
            "Epoch 434/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2004 - val_loss: 0.2246\n",
            "Epoch 435/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1965 - val_loss: 0.2236\n",
            "Epoch 436/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1953 - val_loss: 0.2296\n",
            "Epoch 437/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1981 - val_loss: 0.2333\n",
            "Epoch 438/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1985 - val_loss: 0.2260\n",
            "Epoch 439/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1969 - val_loss: 0.2317\n",
            "Epoch 440/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1981 - val_loss: 0.2242\n",
            "Epoch 441/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2002 - val_loss: 0.2372\n",
            "Epoch 442/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1977 - val_loss: 0.2347\n",
            "Epoch 443/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1971 - val_loss: 0.2278\n",
            "Epoch 444/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1949 - val_loss: 0.2307\n",
            "Epoch 445/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2016 - val_loss: 0.2232\n",
            "Epoch 446/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1945 - val_loss: 0.2212\n",
            "Epoch 447/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1940 - val_loss: 0.2221\n",
            "Epoch 448/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1963 - val_loss: 0.2297\n",
            "Epoch 449/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1987 - val_loss: 0.2248\n",
            "Epoch 450/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1959 - val_loss: 0.2223\n",
            "Epoch 451/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1983 - val_loss: 0.2214\n",
            "Epoch 452/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1959 - val_loss: 0.2280\n",
            "Epoch 453/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1934 - val_loss: 0.2265\n",
            "Epoch 454/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1940 - val_loss: 0.2234\n",
            "Epoch 455/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1944 - val_loss: 0.2317\n",
            "Epoch 456/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1963 - val_loss: 0.2217\n",
            "Epoch 457/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1949 - val_loss: 0.2231\n",
            "Epoch 458/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1956 - val_loss: 0.2249\n",
            "Epoch 459/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1939 - val_loss: 0.2299\n",
            "Epoch 460/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1973 - val_loss: 0.2205\n",
            "Epoch 461/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1988 - val_loss: 0.2260\n",
            "Epoch 462/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1953 - val_loss: 0.2264\n",
            "Epoch 463/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1952 - val_loss: 0.2210\n",
            "Epoch 464/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2009 - val_loss: 0.2240\n",
            "Epoch 465/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1953 - val_loss: 0.2289\n",
            "Epoch 466/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1957 - val_loss: 0.2218\n",
            "Epoch 467/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1940 - val_loss: 0.2228\n",
            "Epoch 468/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1969 - val_loss: 0.2234\n",
            "Epoch 469/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1915 - val_loss: 0.2326\n",
            "Epoch 470/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1955 - val_loss: 0.2263\n",
            "Epoch 471/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1952 - val_loss: 0.2308\n",
            "Epoch 472/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1933 - val_loss: 0.2209\n",
            "Epoch 473/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1953 - val_loss: 0.2192\n",
            "Epoch 474/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1930 - val_loss: 0.2228\n",
            "Epoch 475/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1962 - val_loss: 0.2230\n",
            "Epoch 476/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2049 - val_loss: 0.2191\n",
            "Epoch 477/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1955 - val_loss: 0.2189\n",
            "Epoch 478/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2030 - val_loss: 0.2315\n",
            "Epoch 479/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1958 - val_loss: 0.2211\n",
            "Epoch 480/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1935 - val_loss: 0.2223\n",
            "Epoch 481/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1911 - val_loss: 0.2305\n",
            "Epoch 482/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1944 - val_loss: 0.2207\n",
            "Epoch 483/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1934 - val_loss: 0.2209\n",
            "Epoch 484/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.2234\n",
            "Epoch 485/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1954 - val_loss: 0.2226\n",
            "Epoch 486/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1927 - val_loss: 0.2207\n",
            "Epoch 487/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1906 - val_loss: 0.2239\n",
            "Epoch 488/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1943 - val_loss: 0.2241\n",
            "Epoch 489/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1930 - val_loss: 0.2297\n",
            "Epoch 490/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1930 - val_loss: 0.2225\n",
            "Epoch 491/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1955 - val_loss: 0.2232\n",
            "Epoch 492/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1963 - val_loss: 0.2375\n",
            "Epoch 493/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2025 - val_loss: 0.2242\n",
            "Epoch 494/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1966 - val_loss: 0.2229\n",
            "Epoch 495/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1944 - val_loss: 0.2211\n",
            "Epoch 496/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1929 - val_loss: 0.2205\n",
            "Epoch 497/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1950 - val_loss: 0.2209\n",
            "Epoch 498/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1940 - val_loss: 0.2289\n",
            "Epoch 499/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1974 - val_loss: 0.2171\n",
            "Epoch 500/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1881 - val_loss: 0.2301\n",
            "Epoch 501/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1942 - val_loss: 0.2379\n",
            "Epoch 502/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2009 - val_loss: 0.2254\n",
            "Epoch 503/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1934 - val_loss: 0.2228\n",
            "Epoch 504/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1938 - val_loss: 0.2189\n",
            "Epoch 505/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1910 - val_loss: 0.2233\n",
            "Epoch 506/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1913 - val_loss: 0.2204\n",
            "Epoch 507/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1922 - val_loss: 0.2295\n",
            "Epoch 508/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1947 - val_loss: 0.2202\n",
            "Epoch 509/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1927 - val_loss: 0.2224\n",
            "Epoch 510/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1965 - val_loss: 0.2214\n",
            "Epoch 511/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1970 - val_loss: 0.2253\n",
            "Epoch 512/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1904 - val_loss: 0.2215\n",
            "Epoch 513/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1911 - val_loss: 0.2223\n",
            "Epoch 514/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1922 - val_loss: 0.2250\n",
            "Epoch 515/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1945 - val_loss: 0.2226\n",
            "Epoch 516/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1893 - val_loss: 0.2280\n",
            "Epoch 517/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1999 - val_loss: 0.2187\n",
            "Epoch 518/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1886 - val_loss: 0.2258\n",
            "Epoch 519/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1974 - val_loss: 0.2211\n",
            "Epoch 520/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1930 - val_loss: 0.2192\n",
            "Epoch 521/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1907 - val_loss: 0.2196\n",
            "Epoch 522/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1914 - val_loss: 0.2220\n",
            "Epoch 523/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1910 - val_loss: 0.2213\n",
            "Epoch 524/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1897 - val_loss: 0.2182\n",
            "Epoch 525/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1902 - val_loss: 0.2210\n",
            "Epoch 526/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1904 - val_loss: 0.2269\n",
            "Epoch 527/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1916 - val_loss: 0.2250\n",
            "Epoch 528/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1907 - val_loss: 0.2196\n",
            "Epoch 529/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1970 - val_loss: 0.2228\n",
            "Epoch 530/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1907 - val_loss: 0.2182\n",
            "Epoch 531/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.2205\n",
            "Epoch 532/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.2186\n",
            "Epoch 533/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1917 - val_loss: 0.2198\n",
            "Epoch 534/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1934 - val_loss: 0.2183\n",
            "Epoch 535/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1887 - val_loss: 0.2191\n",
            "Epoch 536/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1886 - val_loss: 0.2183\n",
            "Epoch 537/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1890 - val_loss: 0.2215\n",
            "Epoch 538/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1877 - val_loss: 0.2186\n",
            "Epoch 539/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1911 - val_loss: 0.2192\n",
            "Epoch 540/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1898 - val_loss: 0.2232\n",
            "Epoch 541/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1934 - val_loss: 0.2215\n",
            "Epoch 542/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1905 - val_loss: 0.2221\n",
            "Epoch 543/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1898 - val_loss: 0.2157\n",
            "Epoch 544/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1899 - val_loss: 0.2201\n",
            "Epoch 545/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1904 - val_loss: 0.2166\n",
            "Epoch 546/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1876 - val_loss: 0.2183\n",
            "Epoch 547/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1885 - val_loss: 0.2194\n",
            "Epoch 548/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1941 - val_loss: 0.2188\n",
            "Epoch 549/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1877 - val_loss: 0.2248\n",
            "Epoch 550/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1892 - val_loss: 0.2172\n",
            "Epoch 551/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1883 - val_loss: 0.2221\n",
            "Epoch 552/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1925 - val_loss: 0.2181\n",
            "Epoch 553/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1902 - val_loss: 0.2285\n",
            "Epoch 554/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1895 - val_loss: 0.2332\n",
            "Epoch 555/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1900 - val_loss: 0.2182\n",
            "Epoch 556/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1850 - val_loss: 0.2158\n",
            "Epoch 557/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1897 - val_loss: 0.2291\n",
            "Epoch 558/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1895 - val_loss: 0.2176\n",
            "Epoch 559/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1889 - val_loss: 0.2197\n",
            "Epoch 560/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.2254\n",
            "Epoch 561/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1933 - val_loss: 0.2187\n",
            "Epoch 562/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1852 - val_loss: 0.2273\n",
            "Epoch 563/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1884 - val_loss: 0.2165\n",
            "Epoch 564/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1877 - val_loss: 0.2278\n",
            "Epoch 565/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.2277\n",
            "Epoch 566/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1893 - val_loss: 0.2192\n",
            "Epoch 567/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.2300\n",
            "Epoch 568/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1862 - val_loss: 0.2340\n",
            "Epoch 569/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1900 - val_loss: 0.2236\n",
            "Epoch 570/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1911 - val_loss: 0.2136\n",
            "Epoch 571/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1852 - val_loss: 0.2270\n",
            "Epoch 572/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1894 - val_loss: 0.2243\n",
            "Epoch 573/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1900 - val_loss: 0.2192\n",
            "Epoch 574/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1923 - val_loss: 0.2369\n",
            "Epoch 575/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1907 - val_loss: 0.2196\n",
            "Epoch 576/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1867 - val_loss: 0.2208\n",
            "Epoch 577/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1891 - val_loss: 0.2394\n",
            "Epoch 578/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1941 - val_loss: 0.2284\n",
            "Epoch 579/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1977 - val_loss: 0.2188\n",
            "Epoch 580/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1904 - val_loss: 0.2195\n",
            "Epoch 581/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1888 - val_loss: 0.2270\n",
            "Epoch 582/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1919 - val_loss: 0.2221\n",
            "Epoch 583/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1887 - val_loss: 0.2200\n",
            "Epoch 584/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1878 - val_loss: 0.2270\n",
            "Epoch 585/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1864 - val_loss: 0.2180\n",
            "Epoch 586/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 0.2181\n",
            "Epoch 587/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1873 - val_loss: 0.2249\n",
            "Epoch 588/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1850 - val_loss: 0.2215\n",
            "Epoch 589/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1900 - val_loss: 0.2169\n",
            "Epoch 590/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1853 - val_loss: 0.2255\n",
            "Epoch 591/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1908 - val_loss: 0.2358\n",
            "Epoch 592/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1906 - val_loss: 0.2189\n",
            "Epoch 593/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1866 - val_loss: 0.2165\n",
            "Epoch 594/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1854 - val_loss: 0.2145\n",
            "Epoch 595/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1888 - val_loss: 0.2157\n",
            "Epoch 596/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1852 - val_loss: 0.2206\n",
            "Epoch 597/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1882 - val_loss: 0.2325\n",
            "Epoch 598/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.2185\n",
            "Epoch 599/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1855 - val_loss: 0.2164\n",
            "Epoch 600/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1849 - val_loss: 0.2200\n",
            "Epoch 601/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1879 - val_loss: 0.2153\n",
            "Epoch 602/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1887 - val_loss: 0.2244\n",
            "Epoch 603/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1869 - val_loss: 0.2153\n",
            "Epoch 604/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1870 - val_loss: 0.2250\n",
            "Epoch 605/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1846 - val_loss: 0.2168\n",
            "Epoch 606/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1845 - val_loss: 0.2239\n",
            "Epoch 607/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1876 - val_loss: 0.2185\n",
            "Epoch 608/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1864 - val_loss: 0.2160\n",
            "Epoch 609/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1858 - val_loss: 0.2161\n",
            "Epoch 610/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1859 - val_loss: 0.2208\n",
            "Epoch 611/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1874 - val_loss: 0.2236\n",
            "Epoch 612/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1885 - val_loss: 0.2203\n",
            "Epoch 613/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1873 - val_loss: 0.2199\n",
            "Epoch 614/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1849 - val_loss: 0.2144\n",
            "Epoch 615/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1832 - val_loss: 0.2224\n",
            "Epoch 616/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.2217\n",
            "Epoch 617/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1858 - val_loss: 0.2126\n",
            "Epoch 618/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 0.2130\n",
            "Epoch 619/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1841 - val_loss: 0.2206\n",
            "Epoch 620/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1853 - val_loss: 0.2117\n",
            "Epoch 621/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1853 - val_loss: 0.2153\n",
            "Epoch 622/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1897 - val_loss: 0.2171\n",
            "Epoch 623/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1898 - val_loss: 0.2143\n",
            "Epoch 624/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1863 - val_loss: 0.2142\n",
            "Epoch 625/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1896 - val_loss: 0.2200\n",
            "Epoch 626/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1910 - val_loss: 0.2348\n",
            "Epoch 627/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1899 - val_loss: 0.2145\n",
            "Epoch 628/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1830 - val_loss: 0.2191\n",
            "Epoch 629/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1814 - val_loss: 0.2152\n",
            "Epoch 630/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1883 - val_loss: 0.2228\n",
            "Epoch 631/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.2188\n",
            "Epoch 632/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1875 - val_loss: 0.2229\n",
            "Epoch 633/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1831 - val_loss: 0.2133\n",
            "Epoch 634/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1855 - val_loss: 0.2164\n",
            "Epoch 635/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1884 - val_loss: 0.2182\n",
            "Epoch 636/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1901 - val_loss: 0.2160\n",
            "Epoch 637/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1827 - val_loss: 0.2150\n",
            "Epoch 638/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1830 - val_loss: 0.2191\n",
            "Epoch 639/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1827 - val_loss: 0.2122\n",
            "Epoch 640/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1865 - val_loss: 0.2187\n",
            "Epoch 641/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1847 - val_loss: 0.2157\n",
            "Epoch 642/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1912 - val_loss: 0.2450\n",
            "Epoch 643/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1892 - val_loss: 0.2154\n",
            "Epoch 644/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1869 - val_loss: 0.2208\n",
            "Epoch 645/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1846 - val_loss: 0.2149\n",
            "Epoch 646/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1864 - val_loss: 0.2209\n",
            "Epoch 647/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1856 - val_loss: 0.2152\n",
            "Epoch 648/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1855 - val_loss: 0.2227\n",
            "Epoch 649/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1854 - val_loss: 0.2136\n",
            "Epoch 650/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1848 - val_loss: 0.2149\n",
            "Epoch 651/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1850 - val_loss: 0.2108\n",
            "Epoch 652/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1823 - val_loss: 0.2175\n",
            "Epoch 653/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1890 - val_loss: 0.2318\n",
            "Epoch 654/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1967 - val_loss: 0.2187\n",
            "Epoch 655/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1881 - val_loss: 0.2260\n",
            "Epoch 656/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1833 - val_loss: 0.2156\n",
            "Epoch 657/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1841 - val_loss: 0.2130\n",
            "Epoch 658/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1831 - val_loss: 0.2162\n",
            "Epoch 659/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1837 - val_loss: 0.2164\n",
            "Epoch 660/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1848 - val_loss: 0.2197\n",
            "Epoch 661/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1847 - val_loss: 0.2141\n",
            "Epoch 662/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1834 - val_loss: 0.2159\n",
            "Epoch 663/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1836 - val_loss: 0.2118\n",
            "Epoch 664/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1811 - val_loss: 0.2125\n",
            "Epoch 665/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1830 - val_loss: 0.2120\n",
            "Epoch 666/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1806 - val_loss: 0.2144\n",
            "Epoch 667/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1835 - val_loss: 0.2164\n",
            "Epoch 668/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1813 - val_loss: 0.2259\n",
            "Epoch 669/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1822 - val_loss: 0.2212\n",
            "Epoch 670/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1838 - val_loss: 0.2146\n",
            "Epoch 671/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1811 - val_loss: 0.2157\n",
            "Epoch 672/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1865 - val_loss: 0.2216\n",
            "Epoch 673/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1825 - val_loss: 0.2119\n",
            "Epoch 674/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1800 - val_loss: 0.2179\n",
            "Epoch 675/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1836 - val_loss: 0.2190\n",
            "Epoch 676/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1828 - val_loss: 0.2265\n",
            "Epoch 677/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.2124\n",
            "Epoch 678/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1841 - val_loss: 0.2142\n",
            "Epoch 679/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1833 - val_loss: 0.2160\n",
            "Epoch 680/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1852 - val_loss: 0.2119\n",
            "Epoch 681/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1806 - val_loss: 0.2155\n",
            "Epoch 682/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1823 - val_loss: 0.2148\n",
            "Epoch 683/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1814 - val_loss: 0.2189\n",
            "Epoch 684/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1864 - val_loss: 0.2095\n",
            "Epoch 685/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1836 - val_loss: 0.2134\n",
            "Epoch 686/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1813 - val_loss: 0.2131\n",
            "Epoch 687/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1812 - val_loss: 0.2134\n",
            "Epoch 688/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1811 - val_loss: 0.2253\n",
            "Epoch 689/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1798 - val_loss: 0.2165\n",
            "Epoch 690/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1974 - val_loss: 0.2226\n",
            "Epoch 691/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1841 - val_loss: 0.2113\n",
            "Epoch 692/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1794 - val_loss: 0.2110\n",
            "Epoch 693/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1818 - val_loss: 0.2110\n",
            "Epoch 694/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1847 - val_loss: 0.2185\n",
            "Epoch 695/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1834 - val_loss: 0.2134\n",
            "Epoch 696/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1813 - val_loss: 0.2187\n",
            "Epoch 697/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1835 - val_loss: 0.2137\n",
            "Epoch 698/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1801 - val_loss: 0.2103\n",
            "Epoch 699/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1812 - val_loss: 0.2125\n",
            "Epoch 700/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1796 - val_loss: 0.2128\n",
            "Epoch 701/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1818 - val_loss: 0.2137\n",
            "Epoch 702/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1791 - val_loss: 0.2183\n",
            "Epoch 703/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1818 - val_loss: 0.2153\n",
            "Epoch 704/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1811 - val_loss: 0.2125\n",
            "Epoch 705/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1835 - val_loss: 0.2115\n",
            "Epoch 706/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1813 - val_loss: 0.2121\n",
            "Epoch 707/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1834 - val_loss: 0.2280\n",
            "Epoch 708/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1781 - val_loss: 0.2157\n",
            "Epoch 709/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1900 - val_loss: 0.2221\n",
            "Epoch 710/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1883 - val_loss: 0.2216\n",
            "Epoch 711/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1849 - val_loss: 0.2123\n",
            "Epoch 712/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1815 - val_loss: 0.2116\n",
            "Epoch 713/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1805 - val_loss: 0.2115\n",
            "Epoch 714/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1797 - val_loss: 0.2187\n",
            "Epoch 715/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1889 - val_loss: 0.2346\n",
            "Epoch 716/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1855 - val_loss: 0.2115\n",
            "Epoch 717/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1829 - val_loss: 0.2243\n",
            "Epoch 718/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1821 - val_loss: 0.2147\n",
            "Epoch 719/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1834 - val_loss: 0.2119\n",
            "Epoch 720/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1852 - val_loss: 0.2168\n",
            "Epoch 721/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1805 - val_loss: 0.2234\n",
            "Epoch 722/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1809 - val_loss: 0.2156\n",
            "Epoch 723/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1783 - val_loss: 0.2166\n",
            "Epoch 724/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1876 - val_loss: 0.2191\n",
            "Epoch 725/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1807 - val_loss: 0.2194\n",
            "Epoch 726/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1810 - val_loss: 0.2129\n",
            "Epoch 727/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1800 - val_loss: 0.2103\n",
            "Epoch 728/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1782 - val_loss: 0.2154\n",
            "Epoch 729/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1798 - val_loss: 0.2112\n",
            "Epoch 730/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1806 - val_loss: 0.2155\n",
            "Epoch 731/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1856 - val_loss: 0.2139\n",
            "Epoch 732/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1772 - val_loss: 0.2143\n",
            "Epoch 733/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1794 - val_loss: 0.2126\n",
            "Epoch 734/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1778 - val_loss: 0.2124\n",
            "Epoch 734: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4c66884b90>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ],
      "metadata": {
        "id": "xRmptkSU-0Rw"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses.plot()\n",
        "plt.savefig('loss.png',dpi = 1200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "jDF2jIzg_IqP",
        "outputId": "e892f481-50cd-406b-c265-7310f7b1bf56"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype('int32')"
      ],
      "metadata": {
        "id": "ZPHuP4yx_JWV"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "5nYiV5DXEXKG"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-K0vxOwEZxM",
        "outputId": "26fcfbba-9a8c-414b-989c-96bdc2a2f2e2"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.87      0.90       325\n",
            "           1       0.88      0.93      0.91       323\n",
            "\n",
            "    accuracy                           0.90       648\n",
            "   macro avg       0.91      0.90      0.90       648\n",
            "weighted avg       0.91      0.90      0.90       648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRbA9wX0Ed4Z",
        "outputId": "5910333d-f94f-4972-cd6e-a2d127d42f86"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[284  41]\n",
            " [ 21 302]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(284+302) / (41+21 + 284 + 302)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LDnTP54EspY",
        "outputId": "9fe7134c-8b49-4d9d-f7b1-12c435cbe987"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.904320987654321"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_JDHLmPmEwM1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}