{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Imola.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nT9UeLbL3tq-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "En25u59w3zlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "PnL4eIyK317X",
        "outputId": "daa08fa7-820d-4085-8b85-9e3ac9d2825f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5ffba7bd-81b9-4aa0-9b69-d51b54a0cdf8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5ffba7bd-81b9-4aa0-9b69-d51b54a0cdf8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Imola_GP.csv to Imola_GP.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Imola_GP.csv')"
      ],
      "metadata": {
        "id": "5Gx8y7RL35zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "9NvWt-ee3-k6",
        "outputId": "8d0b3126-6155-4bd5-ed27-0e5290813d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                    Time  DriverNumber                 LapTime  \\\n",
              "0           0  0 days 01:03:54.806000             1                     NaN   \n",
              "1           1  0 days 01:06:20.801000             1  0 days 00:02:25.995000   \n",
              "2           2  0 days 01:08:37.301000             1  0 days 00:02:16.500000   \n",
              "3           3  0 days 01:11:04.728000             1  0 days 00:02:27.427000   \n",
              "4           4  0 days 01:12:36.178000             1  0 days 00:01:31.450000   \n",
              "\n",
              "   LapNumber  Stint              PitOutTime PitInTime             Sector1Time  \\\n",
              "0        1.0    1.0  0 days 00:25:08.250000       NaN                     NaN   \n",
              "1        2.0    1.0                     NaN       NaN  0 days 00:00:54.085000   \n",
              "2        3.0    1.0                     NaN       NaN  0 days 00:00:45.833000   \n",
              "3        4.0    1.0                     NaN       NaN  0 days 00:00:42.546000   \n",
              "4        5.0    1.0                     NaN       NaN  0 days 00:00:29.619000   \n",
              "\n",
              "              Sector2Time  ... SpeedST      Compound TyreLife FreshTyre  \\\n",
              "0  0 days 00:00:31.809000  ...   100.0  INTERMEDIATE      1.0      True   \n",
              "1  0 days 00:00:47.410000  ...   133.0  INTERMEDIATE      2.0      True   \n",
              "2  0 days 00:00:46.168000  ...   164.0  INTERMEDIATE      3.0      True   \n",
              "3  0 days 00:00:48.335000  ...   101.0  INTERMEDIATE      4.0      True   \n",
              "4  0 days 00:00:30.801000  ...   273.0  INTERMEDIATE      5.0      True   \n",
              "\n",
              "             LapStartTime      Team  Driver  TrackStatus IsAccurate  \\\n",
              "0  0 days 01:02:03.225000  Red Bull     VER           24      False   \n",
              "1  0 days 01:03:54.806000  Red Bull     VER            4      False   \n",
              "2  0 days 01:06:20.801000  Red Bull     VER            4      False   \n",
              "3  0 days 01:08:37.301000  Red Bull     VER            4      False   \n",
              "4  0 days 01:11:04.728000  Red Bull     VER            1      False   \n",
              "\n",
              "              LapStartDate  \n",
              "0  2022-04-24 13:03:03.238  \n",
              "1  2022-04-24 13:04:54.819  \n",
              "2  2022-04-24 13:07:20.814  \n",
              "3  2022-04-24 13:09:37.314  \n",
              "4  2022-04-24 13:12:04.741  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c780fc6e-a009-4607-9daa-2dfa7eab6d8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Time</th>\n",
              "      <th>DriverNumber</th>\n",
              "      <th>LapTime</th>\n",
              "      <th>LapNumber</th>\n",
              "      <th>Stint</th>\n",
              "      <th>PitOutTime</th>\n",
              "      <th>PitInTime</th>\n",
              "      <th>Sector1Time</th>\n",
              "      <th>Sector2Time</th>\n",
              "      <th>...</th>\n",
              "      <th>SpeedST</th>\n",
              "      <th>Compound</th>\n",
              "      <th>TyreLife</th>\n",
              "      <th>FreshTyre</th>\n",
              "      <th>LapStartTime</th>\n",
              "      <th>Team</th>\n",
              "      <th>Driver</th>\n",
              "      <th>TrackStatus</th>\n",
              "      <th>IsAccurate</th>\n",
              "      <th>LapStartDate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0 days 01:03:54.806000</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0 days 00:25:08.250000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0 days 00:00:31.809000</td>\n",
              "      <td>...</td>\n",
              "      <td>100.0</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0 days 01:02:03.225000</td>\n",
              "      <td>Red Bull</td>\n",
              "      <td>VER</td>\n",
              "      <td>24</td>\n",
              "      <td>False</td>\n",
              "      <td>2022-04-24 13:03:03.238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0 days 01:06:20.801000</td>\n",
              "      <td>1</td>\n",
              "      <td>0 days 00:02:25.995000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0 days 00:00:54.085000</td>\n",
              "      <td>0 days 00:00:47.410000</td>\n",
              "      <td>...</td>\n",
              "      <td>133.0</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>2.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0 days 01:03:54.806000</td>\n",
              "      <td>Red Bull</td>\n",
              "      <td>VER</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>2022-04-24 13:04:54.819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0 days 01:08:37.301000</td>\n",
              "      <td>1</td>\n",
              "      <td>0 days 00:02:16.500000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0 days 00:00:45.833000</td>\n",
              "      <td>0 days 00:00:46.168000</td>\n",
              "      <td>...</td>\n",
              "      <td>164.0</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>3.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0 days 01:06:20.801000</td>\n",
              "      <td>Red Bull</td>\n",
              "      <td>VER</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>2022-04-24 13:07:20.814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0 days 01:11:04.728000</td>\n",
              "      <td>1</td>\n",
              "      <td>0 days 00:02:27.427000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0 days 00:00:42.546000</td>\n",
              "      <td>0 days 00:00:48.335000</td>\n",
              "      <td>...</td>\n",
              "      <td>101.0</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>4.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0 days 01:08:37.301000</td>\n",
              "      <td>Red Bull</td>\n",
              "      <td>VER</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>2022-04-24 13:09:37.314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0 days 01:12:36.178000</td>\n",
              "      <td>1</td>\n",
              "      <td>0 days 00:01:31.450000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0 days 00:00:29.619000</td>\n",
              "      <td>0 days 00:00:30.801000</td>\n",
              "      <td>...</td>\n",
              "      <td>273.0</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>5.0</td>\n",
              "      <td>True</td>\n",
              "      <td>0 days 01:11:04.728000</td>\n",
              "      <td>Red Bull</td>\n",
              "      <td>VER</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>2022-04-24 13:12:04.741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c780fc6e-a009-4607-9daa-2dfa7eab6d8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c780fc6e-a009-4607-9daa-2dfa7eab6d8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c780fc6e-a009-4607-9daa-2dfa7eab6d8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import f1_preprocessor\n",
        "from f1_preprocessor import cleaning"
      ],
      "metadata": {
        "id": "CjhDhGdt3_AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = cleaning(df)"
      ],
      "metadata": {
        "id": "3jbdIDwl4aKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9drvWHkGqqC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.pivot_table(index = 'PitInTime', aggfunc = 'size').plot(kind='bar',title='Label Imbalances')\n",
        "plt.savefig('imola_label_imbalance.png',dpi = 1200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "a09hcZtM4b63",
        "outputId": "256d983c-941b-4de7-f2b6-f90abf0558e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHhsWd3S6GnJ",
        "outputId": "ffb69996-fb58-4af1-97f1-04ed64f0050b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1104 entries, 1 to 1131\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   LapTime      1104 non-null   float64\n",
            " 1   LapNumber    1104 non-null   float64\n",
            " 2   Stint        1104 non-null   float64\n",
            " 3   PitOutTime   1104 non-null   object \n",
            " 4   PitInTime    1104 non-null   object \n",
            " 5   Sector1Time  1104 non-null   float64\n",
            " 6   Sector2Time  1104 non-null   float64\n",
            " 7   Sector3Time  1104 non-null   float64\n",
            " 8   Compound     1104 non-null   int64  \n",
            " 9   TyreLife     1104 non-null   float64\n",
            " 10  Team         1104 non-null   object \n",
            " 11  Driver       1104 non-null   object \n",
            "dtypes: float64(7), int64(1), object(4)\n",
            "memory usage: 112.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.astype({'PitInTime':int}, errors = 'raise')\n",
        "df = df.astype({'PitOutTime': int}, errors = 'raise')"
      ],
      "metadata": {
        "id": "rA7GZXDF6lan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LEHa_gs7WZs",
        "outputId": "986f1284-0587-485a-8daa-f3ebe80de64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1104 entries, 1 to 1131\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   LapTime      1104 non-null   float64\n",
            " 1   LapNumber    1104 non-null   float64\n",
            " 2   Stint        1104 non-null   float64\n",
            " 3   PitOutTime   1104 non-null   int64  \n",
            " 4   PitInTime    1104 non-null   int64  \n",
            " 5   Sector1Time  1104 non-null   float64\n",
            " 6   Sector2Time  1104 non-null   float64\n",
            " 7   Sector3Time  1104 non-null   float64\n",
            " 8   Compound     1104 non-null   int64  \n",
            " 9   TyreLife     1104 non-null   float64\n",
            " 10  Team         1104 non-null   object \n",
            " 11  Driver       1104 non-null   object \n",
            "dtypes: float64(7), int64(3), object(2)\n",
            "memory usage: 112.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Team','Driver','Sector3Time'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "R3aqQbVX8S6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USING SMOTE TO POPULATE IMBALANCED DATASET"
      ],
      "metadata": {
        "id": "N02eOtgi7XIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "Wd_zPVU17z1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop(['LapTime'],axis=1)\n",
        "y = df['LapTime']"
      ],
      "metadata": {
        "id": "D-8e-eIC71_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_resampled, y_resampled = SMOTE().fit_resample(df[['LapNumber', 'Stint', 'Sector1Time', 'Sector2Time', 'Compound','TyreLife']],df['PitInTime'])"
      ],
      "metadata": {
        "id": "d0hQNp3M8mi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(y_resampled).value_counts().plot(kind='bar',title='Class Distibution after applying SMOTE',xlabel='Pitstop')\n",
        "plt.savefig('imola_label_balanced.png',dpi = 1200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "X1FvNJfH8yVs",
        "outputId": "37ce6303-87c2-4293-e293-87b8a9a4561d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ljSUxZzR9hsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=101)"
      ],
      "metadata": {
        "id": "Q-PLqH7H9y6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "zTxhZBfc97_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "241-Pckx9_zZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = scaler.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "EFsobexE-BDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "QpQLQtye-DHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "M3CXSc5d-FNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense,Dropout"
      ],
      "metadata": {
        "id": "_t276utY-HxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgMp8U0S-Ka6",
        "outputId": "2f93e743-b77b-4c95-bbce-658d5f43816f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1510, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(6,activation='relu'))\n",
        "model.add(Dense(6,activation='relu'))\n",
        "model.add(Dense(3,activation='relu'))\n",
        "\n",
        "# BINARY CLASSIFICATION\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "XAgQmNBc-MAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "9kfj_Wmh_lrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=50)"
      ],
      "metadata": {
        "id": "r5R6etu5_yLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train,y=y_train,epochs=2000,validation_data=(X_test,y_test),callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs-npxZp-r9N",
        "outputId": "77d77364-1f12-4724-8bfc-3332ef870932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "48/48 [==============================] - 1s 6ms/step - loss: 0.6949 - val_loss: 0.6849\n",
            "Epoch 2/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6799 - val_loss: 0.6758\n",
            "Epoch 3/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6639 - val_loss: 0.6511\n",
            "Epoch 4/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6374 - val_loss: 0.6280\n",
            "Epoch 5/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6161 - val_loss: 0.6102\n",
            "Epoch 6/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5987 - val_loss: 0.5963\n",
            "Epoch 7/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5844 - val_loss: 0.5850\n",
            "Epoch 8/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5729 - val_loss: 0.5739\n",
            "Epoch 9/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5619 - val_loss: 0.5646\n",
            "Epoch 10/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5509 - val_loss: 0.5535\n",
            "Epoch 11/2000\n",
            "48/48 [==============================] - 0s 6ms/step - loss: 0.5411 - val_loss: 0.5434\n",
            "Epoch 12/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5288 - val_loss: 0.5340\n",
            "Epoch 13/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5189 - val_loss: 0.5268\n",
            "Epoch 14/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5092 - val_loss: 0.5159\n",
            "Epoch 15/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5006 - val_loss: 0.5072\n",
            "Epoch 16/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4910 - val_loss: 0.4989\n",
            "Epoch 17/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.4825 - val_loss: 0.4916\n",
            "Epoch 18/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4755 - val_loss: 0.4841\n",
            "Epoch 19/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 0.4770\n",
            "Epoch 20/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.4597 - val_loss: 0.4751\n",
            "Epoch 21/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.4659\n",
            "Epoch 22/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4461 - val_loss: 0.4618\n",
            "Epoch 23/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4410 - val_loss: 0.4560\n",
            "Epoch 24/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4341 - val_loss: 0.4487\n",
            "Epoch 25/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4278 - val_loss: 0.4494\n",
            "Epoch 26/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.4229 - val_loss: 0.4400\n",
            "Epoch 27/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4181 - val_loss: 0.4346\n",
            "Epoch 28/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4140 - val_loss: 0.4333\n",
            "Epoch 29/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4094 - val_loss: 0.4271\n",
            "Epoch 30/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4037 - val_loss: 0.4235\n",
            "Epoch 31/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.4213\n",
            "Epoch 32/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3970 - val_loss: 0.4199\n",
            "Epoch 33/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3940 - val_loss: 0.4151\n",
            "Epoch 34/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3901 - val_loss: 0.4101\n",
            "Epoch 35/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3863 - val_loss: 0.4062\n",
            "Epoch 36/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3826 - val_loss: 0.4042\n",
            "Epoch 37/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.4012\n",
            "Epoch 38/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3778 - val_loss: 0.3992\n",
            "Epoch 39/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3742 - val_loss: 0.3978\n",
            "Epoch 40/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3712 - val_loss: 0.3941\n",
            "Epoch 41/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3702 - val_loss: 0.3929\n",
            "Epoch 42/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3675 - val_loss: 0.3883\n",
            "Epoch 43/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3661 - val_loss: 0.3865\n",
            "Epoch 44/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3634 - val_loss: 0.3858\n",
            "Epoch 45/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3617 - val_loss: 0.3833\n",
            "Epoch 46/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3583 - val_loss: 0.3808\n",
            "Epoch 47/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3566 - val_loss: 0.3814\n",
            "Epoch 48/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3555 - val_loss: 0.3772\n",
            "Epoch 49/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3525 - val_loss: 0.3743\n",
            "Epoch 50/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3508 - val_loss: 0.3734\n",
            "Epoch 51/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3493 - val_loss: 0.3719\n",
            "Epoch 52/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3484 - val_loss: 0.3700\n",
            "Epoch 53/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3681\n",
            "Epoch 54/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3456 - val_loss: 0.3742\n",
            "Epoch 55/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 0.3658\n",
            "Epoch 56/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.3639\n",
            "Epoch 57/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3399 - val_loss: 0.3643\n",
            "Epoch 58/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3399 - val_loss: 0.3614\n",
            "Epoch 59/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3386 - val_loss: 0.3597\n",
            "Epoch 60/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3359 - val_loss: 0.3582\n",
            "Epoch 61/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3353 - val_loss: 0.3572\n",
            "Epoch 62/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3329 - val_loss: 0.3561\n",
            "Epoch 63/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3318 - val_loss: 0.3547\n",
            "Epoch 64/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3320 - val_loss: 0.3550\n",
            "Epoch 65/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3311 - val_loss: 0.3526\n",
            "Epoch 66/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.3509\n",
            "Epoch 67/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3279 - val_loss: 0.3524\n",
            "Epoch 68/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.3508\n",
            "Epoch 69/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3274 - val_loss: 0.3489\n",
            "Epoch 70/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3248 - val_loss: 0.3477\n",
            "Epoch 71/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3237 - val_loss: 0.3480\n",
            "Epoch 72/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3233 - val_loss: 0.3452\n",
            "Epoch 73/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3215 - val_loss: 0.3458\n",
            "Epoch 74/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3203 - val_loss: 0.3437\n",
            "Epoch 75/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3200 - val_loss: 0.3459\n",
            "Epoch 76/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3189 - val_loss: 0.3424\n",
            "Epoch 77/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3179 - val_loss: 0.3442\n",
            "Epoch 78/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3219 - val_loss: 0.3456\n",
            "Epoch 79/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3156 - val_loss: 0.3392\n",
            "Epoch 80/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3161 - val_loss: 0.3394\n",
            "Epoch 81/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3149 - val_loss: 0.3380\n",
            "Epoch 82/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.3374\n",
            "Epoch 83/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3129 - val_loss: 0.3369\n",
            "Epoch 84/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.3384\n",
            "Epoch 85/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3136 - val_loss: 0.3378\n",
            "Epoch 86/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3117 - val_loss: 0.3368\n",
            "Epoch 87/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3123 - val_loss: 0.3333\n",
            "Epoch 88/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3097 - val_loss: 0.3330\n",
            "Epoch 89/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3092 - val_loss: 0.3336\n",
            "Epoch 90/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3078 - val_loss: 0.3313\n",
            "Epoch 91/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3084 - val_loss: 0.3309\n",
            "Epoch 92/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3091 - val_loss: 0.3337\n",
            "Epoch 93/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3057 - val_loss: 0.3309\n",
            "Epoch 94/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3062 - val_loss: 0.3327\n",
            "Epoch 95/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3041 - val_loss: 0.3279\n",
            "Epoch 96/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3057 - val_loss: 0.3282\n",
            "Epoch 97/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3040 - val_loss: 0.3275\n",
            "Epoch 98/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3026 - val_loss: 0.3270\n",
            "Epoch 99/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3038 - val_loss: 0.3286\n",
            "Epoch 100/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3017 - val_loss: 0.3287\n",
            "Epoch 101/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3033 - val_loss: 0.3241\n",
            "Epoch 102/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.3238\n",
            "Epoch 103/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3014 - val_loss: 0.3245\n",
            "Epoch 104/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2997 - val_loss: 0.3229\n",
            "Epoch 105/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3005 - val_loss: 0.3211\n",
            "Epoch 106/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2994 - val_loss: 0.3204\n",
            "Epoch 107/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2981 - val_loss: 0.3216\n",
            "Epoch 108/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2984 - val_loss: 0.3197\n",
            "Epoch 109/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2960 - val_loss: 0.3189\n",
            "Epoch 110/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2953 - val_loss: 0.3186\n",
            "Epoch 111/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2943 - val_loss: 0.3190\n",
            "Epoch 112/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2954 - val_loss: 0.3181\n",
            "Epoch 113/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2947 - val_loss: 0.3167\n",
            "Epoch 114/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2942 - val_loss: 0.3157\n",
            "Epoch 115/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2928 - val_loss: 0.3156\n",
            "Epoch 116/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2918 - val_loss: 0.3148\n",
            "Epoch 117/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2921 - val_loss: 0.3207\n",
            "Epoch 118/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2911 - val_loss: 0.3173\n",
            "Epoch 119/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2916 - val_loss: 0.3128\n",
            "Epoch 120/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2909 - val_loss: 0.3145\n",
            "Epoch 121/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2878 - val_loss: 0.3118\n",
            "Epoch 122/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2890 - val_loss: 0.3129\n",
            "Epoch 123/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2874 - val_loss: 0.3131\n",
            "Epoch 124/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2882 - val_loss: 0.3135\n",
            "Epoch 125/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2870 - val_loss: 0.3136\n",
            "Epoch 126/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2888 - val_loss: 0.3098\n",
            "Epoch 127/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2863 - val_loss: 0.3106\n",
            "Epoch 128/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2865 - val_loss: 0.3076\n",
            "Epoch 129/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2858 - val_loss: 0.3082\n",
            "Epoch 130/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2830 - val_loss: 0.3070\n",
            "Epoch 131/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2858 - val_loss: 0.3097\n",
            "Epoch 132/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2829 - val_loss: 0.3047\n",
            "Epoch 133/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2824 - val_loss: 0.3058\n",
            "Epoch 134/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2817 - val_loss: 0.3035\n",
            "Epoch 135/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2791 - val_loss: 0.3049\n",
            "Epoch 136/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2790 - val_loss: 0.3070\n",
            "Epoch 137/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2797 - val_loss: 0.3036\n",
            "Epoch 138/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2805 - val_loss: 0.3018\n",
            "Epoch 139/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2779 - val_loss: 0.3013\n",
            "Epoch 140/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2773 - val_loss: 0.3019\n",
            "Epoch 141/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2773 - val_loss: 0.2994\n",
            "Epoch 142/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2757 - val_loss: 0.2992\n",
            "Epoch 143/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2768 - val_loss: 0.2976\n",
            "Epoch 144/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2758 - val_loss: 0.2966\n",
            "Epoch 145/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2732 - val_loss: 0.2958\n",
            "Epoch 146/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2740 - val_loss: 0.2968\n",
            "Epoch 147/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2716 - val_loss: 0.3018\n",
            "Epoch 148/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2738 - val_loss: 0.2941\n",
            "Epoch 149/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2715 - val_loss: 0.2927\n",
            "Epoch 150/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2706 - val_loss: 0.2912\n",
            "Epoch 151/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2683 - val_loss: 0.2906\n",
            "Epoch 152/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2694 - val_loss: 0.2886\n",
            "Epoch 153/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2694 - val_loss: 0.2932\n",
            "Epoch 154/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2675 - val_loss: 0.2888\n",
            "Epoch 155/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2663 - val_loss: 0.2879\n",
            "Epoch 156/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2639 - val_loss: 0.2908\n",
            "Epoch 157/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2657 - val_loss: 0.2849\n",
            "Epoch 158/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2615 - val_loss: 0.2885\n",
            "Epoch 159/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2624 - val_loss: 0.2824\n",
            "Epoch 160/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2591 - val_loss: 0.2853\n",
            "Epoch 161/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2572 - val_loss: 0.2825\n",
            "Epoch 162/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2586 - val_loss: 0.2887\n",
            "Epoch 163/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2560 - val_loss: 0.2860\n",
            "Epoch 164/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2537 - val_loss: 0.2790\n",
            "Epoch 165/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2539 - val_loss: 0.2783\n",
            "Epoch 166/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2536 - val_loss: 0.2782\n",
            "Epoch 167/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2527 - val_loss: 0.2793\n",
            "Epoch 168/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2541 - val_loss: 0.2783\n",
            "Epoch 169/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2501 - val_loss: 0.2749\n",
            "Epoch 170/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2502 - val_loss: 0.2744\n",
            "Epoch 171/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2492 - val_loss: 0.2745\n",
            "Epoch 172/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2515 - val_loss: 0.2777\n",
            "Epoch 173/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2503 - val_loss: 0.2727\n",
            "Epoch 174/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2487 - val_loss: 0.2716\n",
            "Epoch 175/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2466 - val_loss: 0.2749\n",
            "Epoch 176/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2476 - val_loss: 0.2716\n",
            "Epoch 177/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2459 - val_loss: 0.2719\n",
            "Epoch 178/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2454 - val_loss: 0.2729\n",
            "Epoch 179/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2463 - val_loss: 0.2693\n",
            "Epoch 180/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2498 - val_loss: 0.2716\n",
            "Epoch 181/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2450 - val_loss: 0.2692\n",
            "Epoch 182/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2433 - val_loss: 0.2694\n",
            "Epoch 183/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2438 - val_loss: 0.2660\n",
            "Epoch 184/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2432 - val_loss: 0.2689\n",
            "Epoch 185/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2440 - val_loss: 0.2664\n",
            "Epoch 186/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2438 - val_loss: 0.2651\n",
            "Epoch 187/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2412 - val_loss: 0.2681\n",
            "Epoch 188/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2411 - val_loss: 0.2673\n",
            "Epoch 189/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2382 - val_loss: 0.2647\n",
            "Epoch 190/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2381 - val_loss: 0.2639\n",
            "Epoch 191/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2381 - val_loss: 0.2622\n",
            "Epoch 192/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2383 - val_loss: 0.2625\n",
            "Epoch 193/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2375 - val_loss: 0.2656\n",
            "Epoch 194/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2423 - val_loss: 0.2629\n",
            "Epoch 195/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2379 - val_loss: 0.2604\n",
            "Epoch 196/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2363 - val_loss: 0.2600\n",
            "Epoch 197/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2364 - val_loss: 0.2605\n",
            "Epoch 198/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2370 - val_loss: 0.2615\n",
            "Epoch 199/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2365 - val_loss: 0.2579\n",
            "Epoch 200/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2355 - val_loss: 0.2596\n",
            "Epoch 201/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2336 - val_loss: 0.2606\n",
            "Epoch 202/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2348 - val_loss: 0.2639\n",
            "Epoch 203/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2352 - val_loss: 0.2639\n",
            "Epoch 204/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2424 - val_loss: 0.2557\n",
            "Epoch 205/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2335 - val_loss: 0.2588\n",
            "Epoch 206/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2323 - val_loss: 0.2588\n",
            "Epoch 207/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2325 - val_loss: 0.2577\n",
            "Epoch 208/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2318 - val_loss: 0.2544\n",
            "Epoch 209/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2331 - val_loss: 0.2574\n",
            "Epoch 210/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2310 - val_loss: 0.2553\n",
            "Epoch 211/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2311 - val_loss: 0.2559\n",
            "Epoch 212/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2328 - val_loss: 0.2545\n",
            "Epoch 213/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2289 - val_loss: 0.2547\n",
            "Epoch 214/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2273 - val_loss: 0.2593\n",
            "Epoch 215/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2322 - val_loss: 0.2544\n",
            "Epoch 216/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2285 - val_loss: 0.2549\n",
            "Epoch 217/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2284 - val_loss: 0.2499\n",
            "Epoch 218/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2286 - val_loss: 0.2522\n",
            "Epoch 219/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2271 - val_loss: 0.2528\n",
            "Epoch 220/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2288 - val_loss: 0.2565\n",
            "Epoch 221/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2271 - val_loss: 0.2506\n",
            "Epoch 222/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2270 - val_loss: 0.2524\n",
            "Epoch 223/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2266 - val_loss: 0.2526\n",
            "Epoch 224/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2275 - val_loss: 0.2527\n",
            "Epoch 225/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2302 - val_loss: 0.2476\n",
            "Epoch 226/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2241 - val_loss: 0.2564\n",
            "Epoch 227/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2258 - val_loss: 0.2493\n",
            "Epoch 228/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2255 - val_loss: 0.2484\n",
            "Epoch 229/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2246 - val_loss: 0.2498\n",
            "Epoch 230/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2244 - val_loss: 0.2490\n",
            "Epoch 231/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2243 - val_loss: 0.2494\n",
            "Epoch 232/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2284 - val_loss: 0.2469\n",
            "Epoch 233/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2276 - val_loss: 0.2490\n",
            "Epoch 234/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2248 - val_loss: 0.2474\n",
            "Epoch 235/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2247 - val_loss: 0.2473\n",
            "Epoch 236/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2240 - val_loss: 0.2485\n",
            "Epoch 237/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2239 - val_loss: 0.2466\n",
            "Epoch 238/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2232 - val_loss: 0.2461\n",
            "Epoch 239/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2263 - val_loss: 0.2480\n",
            "Epoch 240/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2223 - val_loss: 0.2493\n",
            "Epoch 241/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2220 - val_loss: 0.2530\n",
            "Epoch 242/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2278 - val_loss: 0.2544\n",
            "Epoch 243/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2269 - val_loss: 0.2513\n",
            "Epoch 244/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2224 - val_loss: 0.2511\n",
            "Epoch 245/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2231 - val_loss: 0.2463\n",
            "Epoch 246/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2225 - val_loss: 0.2486\n",
            "Epoch 247/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2234 - val_loss: 0.2449\n",
            "Epoch 248/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2228 - val_loss: 0.2467\n",
            "Epoch 249/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2181 - val_loss: 0.2472\n",
            "Epoch 250/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2246 - val_loss: 0.2462\n",
            "Epoch 251/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2193 - val_loss: 0.2484\n",
            "Epoch 252/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2188 - val_loss: 0.2471\n",
            "Epoch 253/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2239 - val_loss: 0.2439\n",
            "Epoch 254/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2188 - val_loss: 0.2439\n",
            "Epoch 255/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2210 - val_loss: 0.2440\n",
            "Epoch 256/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2194 - val_loss: 0.2441\n",
            "Epoch 257/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2208 - val_loss: 0.2428\n",
            "Epoch 258/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2190 - val_loss: 0.2449\n",
            "Epoch 259/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2203 - val_loss: 0.2448\n",
            "Epoch 260/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2169 - val_loss: 0.2433\n",
            "Epoch 261/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2183 - val_loss: 0.2447\n",
            "Epoch 262/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2180 - val_loss: 0.2455\n",
            "Epoch 263/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2191 - val_loss: 0.2445\n",
            "Epoch 264/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2181 - val_loss: 0.2458\n",
            "Epoch 265/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2196 - val_loss: 0.2439\n",
            "Epoch 266/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2167 - val_loss: 0.2466\n",
            "Epoch 267/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2174 - val_loss: 0.2478\n",
            "Epoch 268/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2166 - val_loss: 0.2418\n",
            "Epoch 269/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2170 - val_loss: 0.2402\n",
            "Epoch 270/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2168 - val_loss: 0.2439\n",
            "Epoch 271/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2160 - val_loss: 0.2440\n",
            "Epoch 272/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2146 - val_loss: 0.2401\n",
            "Epoch 273/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2148 - val_loss: 0.2417\n",
            "Epoch 274/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2143 - val_loss: 0.2408\n",
            "Epoch 275/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2171 - val_loss: 0.2428\n",
            "Epoch 276/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2146 - val_loss: 0.2418\n",
            "Epoch 277/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2157 - val_loss: 0.2411\n",
            "Epoch 278/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2141 - val_loss: 0.2391\n",
            "Epoch 279/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2132 - val_loss: 0.2416\n",
            "Epoch 280/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2172 - val_loss: 0.2407\n",
            "Epoch 281/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2134 - val_loss: 0.2390\n",
            "Epoch 282/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2126 - val_loss: 0.2406\n",
            "Epoch 283/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2151 - val_loss: 0.2392\n",
            "Epoch 284/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2124 - val_loss: 0.2411\n",
            "Epoch 285/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2120 - val_loss: 0.2472\n",
            "Epoch 286/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2135 - val_loss: 0.2425\n",
            "Epoch 287/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2164 - val_loss: 0.2362\n",
            "Epoch 288/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2177 - val_loss: 0.2373\n",
            "Epoch 289/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2143 - val_loss: 0.2427\n",
            "Epoch 290/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2128 - val_loss: 0.2397\n",
            "Epoch 291/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2185 - val_loss: 0.2419\n",
            "Epoch 292/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2137 - val_loss: 0.2383\n",
            "Epoch 293/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2129 - val_loss: 0.2383\n",
            "Epoch 294/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2116 - val_loss: 0.2361\n",
            "Epoch 295/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2117 - val_loss: 0.2387\n",
            "Epoch 296/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2116 - val_loss: 0.2396\n",
            "Epoch 297/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2127 - val_loss: 0.2425\n",
            "Epoch 298/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2128 - val_loss: 0.2393\n",
            "Epoch 299/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2129 - val_loss: 0.2381\n",
            "Epoch 300/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2108 - val_loss: 0.2456\n",
            "Epoch 301/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2121 - val_loss: 0.2411\n",
            "Epoch 302/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2122 - val_loss: 0.2389\n",
            "Epoch 303/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2109 - val_loss: 0.2383\n",
            "Epoch 304/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2137 - val_loss: 0.2363\n",
            "Epoch 305/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2104 - val_loss: 0.2378\n",
            "Epoch 306/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2109 - val_loss: 0.2374\n",
            "Epoch 307/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2105 - val_loss: 0.2347\n",
            "Epoch 308/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2098 - val_loss: 0.2546\n",
            "Epoch 309/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2153 - val_loss: 0.2410\n",
            "Epoch 310/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2127 - val_loss: 0.2405\n",
            "Epoch 311/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2094 - val_loss: 0.2348\n",
            "Epoch 312/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2088 - val_loss: 0.2360\n",
            "Epoch 313/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2094 - val_loss: 0.2350\n",
            "Epoch 314/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2069 - val_loss: 0.2353\n",
            "Epoch 315/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2133 - val_loss: 0.2364\n",
            "Epoch 316/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2095 - val_loss: 0.2363\n",
            "Epoch 317/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2109 - val_loss: 0.2386\n",
            "Epoch 318/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2105 - val_loss: 0.2355\n",
            "Epoch 319/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2108 - val_loss: 0.2345\n",
            "Epoch 320/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2081 - val_loss: 0.2394\n",
            "Epoch 321/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2169 - val_loss: 0.2349\n",
            "Epoch 322/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2090 - val_loss: 0.2334\n",
            "Epoch 323/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2095 - val_loss: 0.2342\n",
            "Epoch 324/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2071 - val_loss: 0.2343\n",
            "Epoch 325/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2075 - val_loss: 0.2330\n",
            "Epoch 326/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2089 - val_loss: 0.2333\n",
            "Epoch 327/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2108 - val_loss: 0.2300\n",
            "Epoch 328/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2094 - val_loss: 0.2350\n",
            "Epoch 329/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2082 - val_loss: 0.2331\n",
            "Epoch 330/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2084 - val_loss: 0.2330\n",
            "Epoch 331/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2095 - val_loss: 0.2337\n",
            "Epoch 332/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2074 - val_loss: 0.2446\n",
            "Epoch 333/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2092 - val_loss: 0.2368\n",
            "Epoch 334/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2053 - val_loss: 0.2328\n",
            "Epoch 335/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2043 - val_loss: 0.2312\n",
            "Epoch 336/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2080 - val_loss: 0.2312\n",
            "Epoch 337/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2058 - val_loss: 0.2316\n",
            "Epoch 338/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2046 - val_loss: 0.2328\n",
            "Epoch 339/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2063 - val_loss: 0.2339\n",
            "Epoch 340/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2068 - val_loss: 0.2370\n",
            "Epoch 341/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2055 - val_loss: 0.2326\n",
            "Epoch 342/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2086 - val_loss: 0.2296\n",
            "Epoch 343/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2065 - val_loss: 0.2409\n",
            "Epoch 344/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2074 - val_loss: 0.2306\n",
            "Epoch 345/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2046 - val_loss: 0.2374\n",
            "Epoch 346/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2080 - val_loss: 0.2340\n",
            "Epoch 347/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2055 - val_loss: 0.2330\n",
            "Epoch 348/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2083 - val_loss: 0.2331\n",
            "Epoch 349/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2059 - val_loss: 0.2337\n",
            "Epoch 350/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2078 - val_loss: 0.2309\n",
            "Epoch 351/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2055 - val_loss: 0.2311\n",
            "Epoch 352/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2041 - val_loss: 0.2316\n",
            "Epoch 353/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2068 - val_loss: 0.2373\n",
            "Epoch 354/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2075 - val_loss: 0.2302\n",
            "Epoch 355/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2044 - val_loss: 0.2301\n",
            "Epoch 356/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2032 - val_loss: 0.2300\n",
            "Epoch 357/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2072 - val_loss: 0.2329\n",
            "Epoch 358/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2031 - val_loss: 0.2361\n",
            "Epoch 359/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2070 - val_loss: 0.2329\n",
            "Epoch 360/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2041 - val_loss: 0.2284\n",
            "Epoch 361/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2047 - val_loss: 0.2296\n",
            "Epoch 362/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2073 - val_loss: 0.2278\n",
            "Epoch 363/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2047 - val_loss: 0.2299\n",
            "Epoch 364/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2022 - val_loss: 0.2394\n",
            "Epoch 365/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2027 - val_loss: 0.2324\n",
            "Epoch 366/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2020 - val_loss: 0.2287\n",
            "Epoch 367/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2062 - val_loss: 0.2304\n",
            "Epoch 368/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2039 - val_loss: 0.2336\n",
            "Epoch 369/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2056 - val_loss: 0.2284\n",
            "Epoch 370/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2040 - val_loss: 0.2322\n",
            "Epoch 371/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2342\n",
            "Epoch 372/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2038 - val_loss: 0.2292\n",
            "Epoch 373/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2053 - val_loss: 0.2331\n",
            "Epoch 374/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2016 - val_loss: 0.2285\n",
            "Epoch 375/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2037 - val_loss: 0.2382\n",
            "Epoch 376/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2053 - val_loss: 0.2305\n",
            "Epoch 377/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2022 - val_loss: 0.2311\n",
            "Epoch 378/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2020 - val_loss: 0.2328\n",
            "Epoch 379/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2021 - val_loss: 0.2263\n",
            "Epoch 380/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2046 - val_loss: 0.2318\n",
            "Epoch 381/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2017 - val_loss: 0.2279\n",
            "Epoch 382/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2047 - val_loss: 0.2429\n",
            "Epoch 383/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2010 - val_loss: 0.2317\n",
            "Epoch 384/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2010 - val_loss: 0.2275\n",
            "Epoch 385/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2023 - val_loss: 0.2293\n",
            "Epoch 386/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2031 - val_loss: 0.2327\n",
            "Epoch 387/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2023 - val_loss: 0.2291\n",
            "Epoch 388/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2049 - val_loss: 0.2362\n",
            "Epoch 389/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2042 - val_loss: 0.2293\n",
            "Epoch 390/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2019 - val_loss: 0.2332\n",
            "Epoch 391/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2105 - val_loss: 0.2275\n",
            "Epoch 392/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2000 - val_loss: 0.2283\n",
            "Epoch 393/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2060 - val_loss: 0.2305\n",
            "Epoch 394/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2078 - val_loss: 0.2274\n",
            "Epoch 395/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2003 - val_loss: 0.2276\n",
            "Epoch 396/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2026 - val_loss: 0.2268\n",
            "Epoch 397/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1978 - val_loss: 0.2255\n",
            "Epoch 398/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1975 - val_loss: 0.2385\n",
            "Epoch 399/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2000 - val_loss: 0.2311\n",
            "Epoch 400/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2038 - val_loss: 0.2289\n",
            "Epoch 401/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1988 - val_loss: 0.2280\n",
            "Epoch 402/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2398\n",
            "Epoch 403/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2037 - val_loss: 0.2311\n",
            "Epoch 404/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2002 - val_loss: 0.2275\n",
            "Epoch 405/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1997 - val_loss: 0.2263\n",
            "Epoch 406/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2031 - val_loss: 0.2257\n",
            "Epoch 407/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1995 - val_loss: 0.2300\n",
            "Epoch 408/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2025 - val_loss: 0.2269\n",
            "Epoch 409/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2014 - val_loss: 0.2280\n",
            "Epoch 410/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1984 - val_loss: 0.2363\n",
            "Epoch 411/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2000 - val_loss: 0.2284\n",
            "Epoch 412/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2005 - val_loss: 0.2273\n",
            "Epoch 413/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2014 - val_loss: 0.2267\n",
            "Epoch 414/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2005 - val_loss: 0.2287\n",
            "Epoch 415/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1995 - val_loss: 0.2271\n",
            "Epoch 416/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2004 - val_loss: 0.2294\n",
            "Epoch 417/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1990 - val_loss: 0.2331\n",
            "Epoch 418/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2061 - val_loss: 0.2331\n",
            "Epoch 419/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2106 - val_loss: 0.2285\n",
            "Epoch 420/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1988 - val_loss: 0.2260\n",
            "Epoch 421/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1978 - val_loss: 0.2259\n",
            "Epoch 422/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1981 - val_loss: 0.2250\n",
            "Epoch 423/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1971 - val_loss: 0.2255\n",
            "Epoch 424/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1953 - val_loss: 0.2332\n",
            "Epoch 425/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1999 - val_loss: 0.2262\n",
            "Epoch 426/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2029 - val_loss: 0.2261\n",
            "Epoch 427/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2046 - val_loss: 0.2335\n",
            "Epoch 428/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1986 - val_loss: 0.2261\n",
            "Epoch 429/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1954 - val_loss: 0.2274\n",
            "Epoch 430/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2016 - val_loss: 0.2235\n",
            "Epoch 431/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2003 - val_loss: 0.2236\n",
            "Epoch 432/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1957 - val_loss: 0.2238\n",
            "Epoch 433/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1991 - val_loss: 0.2273\n",
            "Epoch 434/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2004 - val_loss: 0.2246\n",
            "Epoch 435/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1965 - val_loss: 0.2236\n",
            "Epoch 436/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1953 - val_loss: 0.2296\n",
            "Epoch 437/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1981 - val_loss: 0.2333\n",
            "Epoch 438/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1985 - val_loss: 0.2260\n",
            "Epoch 439/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1969 - val_loss: 0.2317\n",
            "Epoch 440/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1981 - val_loss: 0.2242\n",
            "Epoch 441/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2002 - val_loss: 0.2372\n",
            "Epoch 442/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1977 - val_loss: 0.2347\n",
            "Epoch 443/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1971 - val_loss: 0.2278\n",
            "Epoch 444/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1949 - val_loss: 0.2307\n",
            "Epoch 445/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2016 - val_loss: 0.2232\n",
            "Epoch 446/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1945 - val_loss: 0.2212\n",
            "Epoch 447/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1940 - val_loss: 0.2221\n",
            "Epoch 448/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1963 - val_loss: 0.2297\n",
            "Epoch 449/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1987 - val_loss: 0.2248\n",
            "Epoch 450/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1959 - val_loss: 0.2223\n",
            "Epoch 451/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1983 - val_loss: 0.2214\n",
            "Epoch 452/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1959 - val_loss: 0.2280\n",
            "Epoch 453/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1934 - val_loss: 0.2265\n",
            "Epoch 454/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1940 - val_loss: 0.2234\n",
            "Epoch 455/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1944 - val_loss: 0.2317\n",
            "Epoch 456/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1963 - val_loss: 0.2217\n",
            "Epoch 457/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1949 - val_loss: 0.2231\n",
            "Epoch 458/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1956 - val_loss: 0.2249\n",
            "Epoch 459/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1939 - val_loss: 0.2299\n",
            "Epoch 460/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1973 - val_loss: 0.2205\n",
            "Epoch 461/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1988 - val_loss: 0.2260\n",
            "Epoch 462/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1953 - val_loss: 0.2264\n",
            "Epoch 463/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1952 - val_loss: 0.2210\n",
            "Epoch 464/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2009 - val_loss: 0.2240\n",
            "Epoch 465/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1953 - val_loss: 0.2289\n",
            "Epoch 466/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1957 - val_loss: 0.2218\n",
            "Epoch 467/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1940 - val_loss: 0.2228\n",
            "Epoch 468/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1969 - val_loss: 0.2234\n",
            "Epoch 469/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1915 - val_loss: 0.2326\n",
            "Epoch 470/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1955 - val_loss: 0.2263\n",
            "Epoch 471/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1952 - val_loss: 0.2308\n",
            "Epoch 472/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1933 - val_loss: 0.2209\n",
            "Epoch 473/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1953 - val_loss: 0.2192\n",
            "Epoch 474/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1930 - val_loss: 0.2228\n",
            "Epoch 475/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1962 - val_loss: 0.2230\n",
            "Epoch 476/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2049 - val_loss: 0.2191\n",
            "Epoch 477/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1955 - val_loss: 0.2189\n",
            "Epoch 478/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2030 - val_loss: 0.2315\n",
            "Epoch 479/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1958 - val_loss: 0.2211\n",
            "Epoch 480/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1935 - val_loss: 0.2223\n",
            "Epoch 481/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1911 - val_loss: 0.2305\n",
            "Epoch 482/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1944 - val_loss: 0.2207\n",
            "Epoch 483/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1934 - val_loss: 0.2209\n",
            "Epoch 484/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.2234\n",
            "Epoch 485/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1954 - val_loss: 0.2226\n",
            "Epoch 486/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1927 - val_loss: 0.2207\n",
            "Epoch 487/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1906 - val_loss: 0.2239\n",
            "Epoch 488/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1943 - val_loss: 0.2241\n",
            "Epoch 489/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1930 - val_loss: 0.2297\n",
            "Epoch 490/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1930 - val_loss: 0.2225\n",
            "Epoch 491/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1955 - val_loss: 0.2232\n",
            "Epoch 492/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1963 - val_loss: 0.2375\n",
            "Epoch 493/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2025 - val_loss: 0.2242\n",
            "Epoch 494/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1966 - val_loss: 0.2229\n",
            "Epoch 495/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1944 - val_loss: 0.2211\n",
            "Epoch 496/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1929 - val_loss: 0.2205\n",
            "Epoch 497/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1950 - val_loss: 0.2209\n",
            "Epoch 498/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1940 - val_loss: 0.2289\n",
            "Epoch 499/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1974 - val_loss: 0.2171\n",
            "Epoch 500/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1881 - val_loss: 0.2301\n",
            "Epoch 501/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1942 - val_loss: 0.2379\n",
            "Epoch 502/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2009 - val_loss: 0.2254\n",
            "Epoch 503/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1934 - val_loss: 0.2228\n",
            "Epoch 504/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1938 - val_loss: 0.2189\n",
            "Epoch 505/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1910 - val_loss: 0.2233\n",
            "Epoch 506/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1913 - val_loss: 0.2204\n",
            "Epoch 507/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1922 - val_loss: 0.2295\n",
            "Epoch 508/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1947 - val_loss: 0.2202\n",
            "Epoch 509/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1927 - val_loss: 0.2224\n",
            "Epoch 510/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1965 - val_loss: 0.2214\n",
            "Epoch 511/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1970 - val_loss: 0.2253\n",
            "Epoch 512/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1904 - val_loss: 0.2215\n",
            "Epoch 513/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1911 - val_loss: 0.2223\n",
            "Epoch 514/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1922 - val_loss: 0.2250\n",
            "Epoch 515/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1945 - val_loss: 0.2226\n",
            "Epoch 516/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1893 - val_loss: 0.2280\n",
            "Epoch 517/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1999 - val_loss: 0.2187\n",
            "Epoch 518/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1886 - val_loss: 0.2258\n",
            "Epoch 519/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1974 - val_loss: 0.2211\n",
            "Epoch 520/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1930 - val_loss: 0.2192\n",
            "Epoch 521/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1907 - val_loss: 0.2196\n",
            "Epoch 522/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1914 - val_loss: 0.2220\n",
            "Epoch 523/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1910 - val_loss: 0.2213\n",
            "Epoch 524/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1897 - val_loss: 0.2182\n",
            "Epoch 525/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1902 - val_loss: 0.2210\n",
            "Epoch 526/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1904 - val_loss: 0.2269\n",
            "Epoch 527/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1916 - val_loss: 0.2250\n",
            "Epoch 528/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1907 - val_loss: 0.2196\n",
            "Epoch 529/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1970 - val_loss: 0.2228\n",
            "Epoch 530/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1907 - val_loss: 0.2182\n",
            "Epoch 531/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.2205\n",
            "Epoch 532/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1936 - val_loss: 0.2186\n",
            "Epoch 533/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1917 - val_loss: 0.2198\n",
            "Epoch 534/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1934 - val_loss: 0.2183\n",
            "Epoch 535/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1887 - val_loss: 0.2191\n",
            "Epoch 536/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1886 - val_loss: 0.2183\n",
            "Epoch 537/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1890 - val_loss: 0.2215\n",
            "Epoch 538/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1877 - val_loss: 0.2186\n",
            "Epoch 539/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1911 - val_loss: 0.2192\n",
            "Epoch 540/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1898 - val_loss: 0.2232\n",
            "Epoch 541/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1934 - val_loss: 0.2215\n",
            "Epoch 542/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1905 - val_loss: 0.2221\n",
            "Epoch 543/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1898 - val_loss: 0.2157\n",
            "Epoch 544/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1899 - val_loss: 0.2201\n",
            "Epoch 545/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1904 - val_loss: 0.2166\n",
            "Epoch 546/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1876 - val_loss: 0.2183\n",
            "Epoch 547/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1885 - val_loss: 0.2194\n",
            "Epoch 548/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1941 - val_loss: 0.2188\n",
            "Epoch 549/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1877 - val_loss: 0.2248\n",
            "Epoch 550/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1892 - val_loss: 0.2172\n",
            "Epoch 551/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1883 - val_loss: 0.2221\n",
            "Epoch 552/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1925 - val_loss: 0.2181\n",
            "Epoch 553/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1902 - val_loss: 0.2285\n",
            "Epoch 554/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1895 - val_loss: 0.2332\n",
            "Epoch 555/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1900 - val_loss: 0.2182\n",
            "Epoch 556/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1850 - val_loss: 0.2158\n",
            "Epoch 557/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1897 - val_loss: 0.2291\n",
            "Epoch 558/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1895 - val_loss: 0.2176\n",
            "Epoch 559/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1889 - val_loss: 0.2197\n",
            "Epoch 560/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.2254\n",
            "Epoch 561/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1933 - val_loss: 0.2187\n",
            "Epoch 562/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1852 - val_loss: 0.2273\n",
            "Epoch 563/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1884 - val_loss: 0.2165\n",
            "Epoch 564/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1877 - val_loss: 0.2278\n",
            "Epoch 565/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.2277\n",
            "Epoch 566/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1893 - val_loss: 0.2192\n",
            "Epoch 567/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.2300\n",
            "Epoch 568/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1862 - val_loss: 0.2340\n",
            "Epoch 569/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1900 - val_loss: 0.2236\n",
            "Epoch 570/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1911 - val_loss: 0.2136\n",
            "Epoch 571/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1852 - val_loss: 0.2270\n",
            "Epoch 572/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1894 - val_loss: 0.2243\n",
            "Epoch 573/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1900 - val_loss: 0.2192\n",
            "Epoch 574/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1923 - val_loss: 0.2369\n",
            "Epoch 575/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1907 - val_loss: 0.2196\n",
            "Epoch 576/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1867 - val_loss: 0.2208\n",
            "Epoch 577/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1891 - val_loss: 0.2394\n",
            "Epoch 578/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1941 - val_loss: 0.2284\n",
            "Epoch 579/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1977 - val_loss: 0.2188\n",
            "Epoch 580/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1904 - val_loss: 0.2195\n",
            "Epoch 581/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1888 - val_loss: 0.2270\n",
            "Epoch 582/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1919 - val_loss: 0.2221\n",
            "Epoch 583/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1887 - val_loss: 0.2200\n",
            "Epoch 584/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1878 - val_loss: 0.2270\n",
            "Epoch 585/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1864 - val_loss: 0.2180\n",
            "Epoch 586/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 0.2181\n",
            "Epoch 587/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1873 - val_loss: 0.2249\n",
            "Epoch 588/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1850 - val_loss: 0.2215\n",
            "Epoch 589/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1900 - val_loss: 0.2169\n",
            "Epoch 590/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1853 - val_loss: 0.2255\n",
            "Epoch 591/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1908 - val_loss: 0.2358\n",
            "Epoch 592/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1906 - val_loss: 0.2189\n",
            "Epoch 593/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1866 - val_loss: 0.2165\n",
            "Epoch 594/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1854 - val_loss: 0.2145\n",
            "Epoch 595/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1888 - val_loss: 0.2157\n",
            "Epoch 596/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1852 - val_loss: 0.2206\n",
            "Epoch 597/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1882 - val_loss: 0.2325\n",
            "Epoch 598/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.2185\n",
            "Epoch 599/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1855 - val_loss: 0.2164\n",
            "Epoch 600/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1849 - val_loss: 0.2200\n",
            "Epoch 601/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1879 - val_loss: 0.2153\n",
            "Epoch 602/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1887 - val_loss: 0.2244\n",
            "Epoch 603/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1869 - val_loss: 0.2153\n",
            "Epoch 604/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1870 - val_loss: 0.2250\n",
            "Epoch 605/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1846 - val_loss: 0.2168\n",
            "Epoch 606/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1845 - val_loss: 0.2239\n",
            "Epoch 607/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1876 - val_loss: 0.2185\n",
            "Epoch 608/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1864 - val_loss: 0.2160\n",
            "Epoch 609/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1858 - val_loss: 0.2161\n",
            "Epoch 610/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1859 - val_loss: 0.2208\n",
            "Epoch 611/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1874 - val_loss: 0.2236\n",
            "Epoch 612/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1885 - val_loss: 0.2203\n",
            "Epoch 613/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1873 - val_loss: 0.2199\n",
            "Epoch 614/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1849 - val_loss: 0.2144\n",
            "Epoch 615/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1832 - val_loss: 0.2224\n",
            "Epoch 616/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1856 - val_loss: 0.2217\n",
            "Epoch 617/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1858 - val_loss: 0.2126\n",
            "Epoch 618/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 0.2130\n",
            "Epoch 619/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1841 - val_loss: 0.2206\n",
            "Epoch 620/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1853 - val_loss: 0.2117\n",
            "Epoch 621/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1853 - val_loss: 0.2153\n",
            "Epoch 622/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1897 - val_loss: 0.2171\n",
            "Epoch 623/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1898 - val_loss: 0.2143\n",
            "Epoch 624/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1863 - val_loss: 0.2142\n",
            "Epoch 625/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1896 - val_loss: 0.2200\n",
            "Epoch 626/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1910 - val_loss: 0.2348\n",
            "Epoch 627/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1899 - val_loss: 0.2145\n",
            "Epoch 628/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1830 - val_loss: 0.2191\n",
            "Epoch 629/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1814 - val_loss: 0.2152\n",
            "Epoch 630/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1883 - val_loss: 0.2228\n",
            "Epoch 631/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.2188\n",
            "Epoch 632/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1875 - val_loss: 0.2229\n",
            "Epoch 633/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1831 - val_loss: 0.2133\n",
            "Epoch 634/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1855 - val_loss: 0.2164\n",
            "Epoch 635/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1884 - val_loss: 0.2182\n",
            "Epoch 636/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1901 - val_loss: 0.2160\n",
            "Epoch 637/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1827 - val_loss: 0.2150\n",
            "Epoch 638/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1830 - val_loss: 0.2191\n",
            "Epoch 639/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1827 - val_loss: 0.2122\n",
            "Epoch 640/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1865 - val_loss: 0.2187\n",
            "Epoch 641/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1847 - val_loss: 0.2157\n",
            "Epoch 642/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1912 - val_loss: 0.2450\n",
            "Epoch 643/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1892 - val_loss: 0.2154\n",
            "Epoch 644/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1869 - val_loss: 0.2208\n",
            "Epoch 645/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1846 - val_loss: 0.2149\n",
            "Epoch 646/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1864 - val_loss: 0.2209\n",
            "Epoch 647/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1856 - val_loss: 0.2152\n",
            "Epoch 648/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1855 - val_loss: 0.2227\n",
            "Epoch 649/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1854 - val_loss: 0.2136\n",
            "Epoch 650/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1848 - val_loss: 0.2149\n",
            "Epoch 651/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1850 - val_loss: 0.2108\n",
            "Epoch 652/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1823 - val_loss: 0.2175\n",
            "Epoch 653/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1890 - val_loss: 0.2318\n",
            "Epoch 654/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1967 - val_loss: 0.2187\n",
            "Epoch 655/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1881 - val_loss: 0.2260\n",
            "Epoch 656/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1833 - val_loss: 0.2156\n",
            "Epoch 657/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1841 - val_loss: 0.2130\n",
            "Epoch 658/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1831 - val_loss: 0.2162\n",
            "Epoch 659/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1837 - val_loss: 0.2164\n",
            "Epoch 660/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1848 - val_loss: 0.2197\n",
            "Epoch 661/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1847 - val_loss: 0.2141\n",
            "Epoch 662/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1834 - val_loss: 0.2159\n",
            "Epoch 663/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1836 - val_loss: 0.2118\n",
            "Epoch 664/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1811 - val_loss: 0.2125\n",
            "Epoch 665/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1830 - val_loss: 0.2120\n",
            "Epoch 666/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1806 - val_loss: 0.2144\n",
            "Epoch 667/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1835 - val_loss: 0.2164\n",
            "Epoch 668/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1813 - val_loss: 0.2259\n",
            "Epoch 669/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1822 - val_loss: 0.2212\n",
            "Epoch 670/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1838 - val_loss: 0.2146\n",
            "Epoch 671/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1811 - val_loss: 0.2157\n",
            "Epoch 672/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1865 - val_loss: 0.2216\n",
            "Epoch 673/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1825 - val_loss: 0.2119\n",
            "Epoch 674/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1800 - val_loss: 0.2179\n",
            "Epoch 675/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1836 - val_loss: 0.2190\n",
            "Epoch 676/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1828 - val_loss: 0.2265\n",
            "Epoch 677/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.2124\n",
            "Epoch 678/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1841 - val_loss: 0.2142\n",
            "Epoch 679/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1833 - val_loss: 0.2160\n",
            "Epoch 680/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1852 - val_loss: 0.2119\n",
            "Epoch 681/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1806 - val_loss: 0.2155\n",
            "Epoch 682/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1823 - val_loss: 0.2148\n",
            "Epoch 683/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1814 - val_loss: 0.2189\n",
            "Epoch 684/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1864 - val_loss: 0.2095\n",
            "Epoch 685/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1836 - val_loss: 0.2134\n",
            "Epoch 686/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1813 - val_loss: 0.2131\n",
            "Epoch 687/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1812 - val_loss: 0.2134\n",
            "Epoch 688/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1811 - val_loss: 0.2253\n",
            "Epoch 689/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1798 - val_loss: 0.2165\n",
            "Epoch 690/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1974 - val_loss: 0.2226\n",
            "Epoch 691/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1841 - val_loss: 0.2113\n",
            "Epoch 692/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1794 - val_loss: 0.2110\n",
            "Epoch 693/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1818 - val_loss: 0.2110\n",
            "Epoch 694/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1847 - val_loss: 0.2185\n",
            "Epoch 695/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1834 - val_loss: 0.2134\n",
            "Epoch 696/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1813 - val_loss: 0.2187\n",
            "Epoch 697/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1835 - val_loss: 0.2137\n",
            "Epoch 698/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1801 - val_loss: 0.2103\n",
            "Epoch 699/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1812 - val_loss: 0.2125\n",
            "Epoch 700/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1796 - val_loss: 0.2128\n",
            "Epoch 701/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1818 - val_loss: 0.2137\n",
            "Epoch 702/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1791 - val_loss: 0.2183\n",
            "Epoch 703/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1818 - val_loss: 0.2153\n",
            "Epoch 704/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1811 - val_loss: 0.2125\n",
            "Epoch 705/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1835 - val_loss: 0.2115\n",
            "Epoch 706/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1813 - val_loss: 0.2121\n",
            "Epoch 707/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1834 - val_loss: 0.2280\n",
            "Epoch 708/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1781 - val_loss: 0.2157\n",
            "Epoch 709/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1900 - val_loss: 0.2221\n",
            "Epoch 710/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1883 - val_loss: 0.2216\n",
            "Epoch 711/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1849 - val_loss: 0.2123\n",
            "Epoch 712/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1815 - val_loss: 0.2116\n",
            "Epoch 713/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1805 - val_loss: 0.2115\n",
            "Epoch 714/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1797 - val_loss: 0.2187\n",
            "Epoch 715/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1889 - val_loss: 0.2346\n",
            "Epoch 716/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1855 - val_loss: 0.2115\n",
            "Epoch 717/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1829 - val_loss: 0.2243\n",
            "Epoch 718/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.1821 - val_loss: 0.2147\n",
            "Epoch 719/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1834 - val_loss: 0.2119\n",
            "Epoch 720/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1852 - val_loss: 0.2168\n",
            "Epoch 721/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1805 - val_loss: 0.2234\n",
            "Epoch 722/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1809 - val_loss: 0.2156\n",
            "Epoch 723/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1783 - val_loss: 0.2166\n",
            "Epoch 724/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1876 - val_loss: 0.2191\n",
            "Epoch 725/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1807 - val_loss: 0.2194\n",
            "Epoch 726/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.1810 - val_loss: 0.2129\n",
            "Epoch 727/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1800 - val_loss: 0.2103\n",
            "Epoch 728/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1782 - val_loss: 0.2154\n",
            "Epoch 729/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1798 - val_loss: 0.2112\n",
            "Epoch 730/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1806 - val_loss: 0.2155\n",
            "Epoch 731/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1856 - val_loss: 0.2139\n",
            "Epoch 732/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1772 - val_loss: 0.2143\n",
            "Epoch 733/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1794 - val_loss: 0.2126\n",
            "Epoch 734/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.1778 - val_loss: 0.2124\n",
            "Epoch 734: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4c66884b90>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ],
      "metadata": {
        "id": "xRmptkSU-0Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses.plot()\n",
        "plt.savefig('loss.png',dpi = 1200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "jDF2jIzg_IqP",
        "outputId": "e892f481-50cd-406b-c265-7310f7b1bf56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype('int32')"
      ],
      "metadata": {
        "id": "ZPHuP4yx_JWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "5nYiV5DXEXKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-K0vxOwEZxM",
        "outputId": "26fcfbba-9a8c-414b-989c-96bdc2a2f2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.87      0.90       325\n",
            "           1       0.88      0.93      0.91       323\n",
            "\n",
            "    accuracy                           0.90       648\n",
            "   macro avg       0.91      0.90      0.90       648\n",
            "weighted avg       0.91      0.90      0.90       648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRbA9wX0Ed4Z",
        "outputId": "5910333d-f94f-4972-cd6e-a2d127d42f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[284  41]\n",
            " [ 21 302]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(284+302) / (41+21 + 284 + 302)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LDnTP54EspY",
        "outputId": "9fe7134c-8b49-4d9d-f7b1-12c435cbe987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.904320987654321"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "_JDHLmPmEwM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('imola_pit_model.h5')"
      ],
      "metadata": {
        "id": "Db67Z2mRG-wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(6,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(4,activation='relu'))\n",
        "\n",
        "\n",
        "# BINARY CLASSIFICATION\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "OvyFxCD0HHkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train,y=y_train,epochs=2000,validation_data=(X_test,y_test),callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yPMIZnut92B",
        "outputId": "b8dadc22-b2e3-4b0d-84ab-b0470323ad3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "48/48 [==============================] - 1s 7ms/step - loss: 0.7049 - val_loss: 0.6867\n",
            "Epoch 2/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6895 - val_loss: 0.6741\n",
            "Epoch 3/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6769 - val_loss: 0.6545\n",
            "Epoch 4/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6594 - val_loss: 0.6286\n",
            "Epoch 5/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6452 - val_loss: 0.6134\n",
            "Epoch 6/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6225 - val_loss: 0.6038\n",
            "Epoch 7/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6210 - val_loss: 0.5993\n",
            "Epoch 8/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6164 - val_loss: 0.5948\n",
            "Epoch 9/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.6108 - val_loss: 0.5895\n",
            "Epoch 10/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5960 - val_loss: 0.5855\n",
            "Epoch 11/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5918 - val_loss: 0.5783\n",
            "Epoch 12/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5836 - val_loss: 0.5738\n",
            "Epoch 13/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5889 - val_loss: 0.5705\n",
            "Epoch 14/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5774 - val_loss: 0.5632\n",
            "Epoch 15/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5765 - val_loss: 0.5611\n",
            "Epoch 16/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5756 - val_loss: 0.5593\n",
            "Epoch 17/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5583 - val_loss: 0.5534\n",
            "Epoch 18/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5658 - val_loss: 0.5431\n",
            "Epoch 19/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5424 - val_loss: 0.5347\n",
            "Epoch 20/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5526 - val_loss: 0.5277\n",
            "Epoch 21/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5355 - val_loss: 0.5183\n",
            "Epoch 22/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5335 - val_loss: 0.5128\n",
            "Epoch 23/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5252 - val_loss: 0.4967\n",
            "Epoch 24/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5193 - val_loss: 0.4900\n",
            "Epoch 25/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5090 - val_loss: 0.4980\n",
            "Epoch 26/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5189 - val_loss: 0.4769\n",
            "Epoch 27/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5094 - val_loss: 0.4795\n",
            "Epoch 28/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5002 - val_loss: 0.4679\n",
            "Epoch 29/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5057 - val_loss: 0.4683\n",
            "Epoch 30/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4984 - val_loss: 0.4587\n",
            "Epoch 31/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4868 - val_loss: 0.4585\n",
            "Epoch 32/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4801 - val_loss: 0.4485\n",
            "Epoch 33/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4791 - val_loss: 0.4493\n",
            "Epoch 34/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4888 - val_loss: 0.4536\n",
            "Epoch 35/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4810 - val_loss: 0.4492\n",
            "Epoch 36/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4759 - val_loss: 0.4352\n",
            "Epoch 37/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4718 - val_loss: 0.4385\n",
            "Epoch 38/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4559 - val_loss: 0.4379\n",
            "Epoch 39/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4688 - val_loss: 0.4357\n",
            "Epoch 40/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4518 - val_loss: 0.4286\n",
            "Epoch 41/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4782 - val_loss: 0.4321\n",
            "Epoch 42/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4557 - val_loss: 0.4285\n",
            "Epoch 43/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4478 - val_loss: 0.4192\n",
            "Epoch 44/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4656 - val_loss: 0.4227\n",
            "Epoch 45/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4580 - val_loss: 0.4344\n",
            "Epoch 46/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4520 - val_loss: 0.4194\n",
            "Epoch 47/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4536 - val_loss: 0.4191\n",
            "Epoch 48/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4461 - val_loss: 0.4171\n",
            "Epoch 49/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4474 - val_loss: 0.4087\n",
            "Epoch 50/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4491 - val_loss: 0.4130\n",
            "Epoch 51/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4386 - val_loss: 0.4194\n",
            "Epoch 52/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4212 - val_loss: 0.4084\n",
            "Epoch 53/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4323 - val_loss: 0.4026\n",
            "Epoch 54/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4193 - val_loss: 0.4038\n",
            "Epoch 55/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4291 - val_loss: 0.3936\n",
            "Epoch 56/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4262 - val_loss: 0.4115\n",
            "Epoch 57/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4385 - val_loss: 0.4110\n",
            "Epoch 58/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4325 - val_loss: 0.4098\n",
            "Epoch 59/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4254 - val_loss: 0.4029\n",
            "Epoch 60/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4221 - val_loss: 0.3956\n",
            "Epoch 61/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4270 - val_loss: 0.3960\n",
            "Epoch 62/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4127 - val_loss: 0.4043\n",
            "Epoch 63/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4112 - val_loss: 0.4026\n",
            "Epoch 64/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4079 - val_loss: 0.3918\n",
            "Epoch 65/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4033 - val_loss: 0.3909\n",
            "Epoch 66/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4192 - val_loss: 0.3968\n",
            "Epoch 67/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4225 - val_loss: 0.3816\n",
            "Epoch 68/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4081 - val_loss: 0.3924\n",
            "Epoch 69/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4205 - val_loss: 0.3962\n",
            "Epoch 70/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3990 - val_loss: 0.3885\n",
            "Epoch 71/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3985 - val_loss: 0.3933\n",
            "Epoch 72/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4098 - val_loss: 0.3940\n",
            "Epoch 73/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4031 - val_loss: 0.3750\n",
            "Epoch 74/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3979 - val_loss: 0.3896\n",
            "Epoch 75/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3999 - val_loss: 0.3741\n",
            "Epoch 76/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3912 - val_loss: 0.3861\n",
            "Epoch 77/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3992 - val_loss: 0.3751\n",
            "Epoch 78/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4019 - val_loss: 0.3905\n",
            "Epoch 79/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3802 - val_loss: 0.3783\n",
            "Epoch 80/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4011 - val_loss: 0.3950\n",
            "Epoch 81/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3843 - val_loss: 0.3731\n",
            "Epoch 82/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3783 - val_loss: 0.3738\n",
            "Epoch 83/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3979 - val_loss: 0.3878\n",
            "Epoch 84/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3862 - val_loss: 0.3855\n",
            "Epoch 85/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3814 - val_loss: 0.3735\n",
            "Epoch 86/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3721 - val_loss: 0.3717\n",
            "Epoch 87/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3853 - val_loss: 0.3612\n",
            "Epoch 88/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3913 - val_loss: 0.3681\n",
            "Epoch 89/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3667 - val_loss: 0.3586\n",
            "Epoch 90/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3820 - val_loss: 0.3794\n",
            "Epoch 91/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3803 - val_loss: 0.3838\n",
            "Epoch 92/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3690 - val_loss: 0.3715\n",
            "Epoch 93/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3753 - val_loss: 0.3645\n",
            "Epoch 94/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3714 - val_loss: 0.3634\n",
            "Epoch 95/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3786 - val_loss: 0.3700\n",
            "Epoch 96/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3629 - val_loss: 0.3546\n",
            "Epoch 97/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3856 - val_loss: 0.3612\n",
            "Epoch 98/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3576 - val_loss: 0.3534\n",
            "Epoch 99/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3725 - val_loss: 0.3505\n",
            "Epoch 100/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3736 - val_loss: 0.3569\n",
            "Epoch 101/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3731 - val_loss: 0.3560\n",
            "Epoch 102/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3684 - val_loss: 0.3683\n",
            "Epoch 103/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3750 - val_loss: 0.3491\n",
            "Epoch 104/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3575 - val_loss: 0.3459\n",
            "Epoch 105/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3581 - val_loss: 0.3635\n",
            "Epoch 106/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3571 - val_loss: 0.3542\n",
            "Epoch 107/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3505 - val_loss: 0.3348\n",
            "Epoch 108/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3853 - val_loss: 0.3580\n",
            "Epoch 109/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3670 - val_loss: 0.3626\n",
            "Epoch 110/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3588 - val_loss: 0.3540\n",
            "Epoch 111/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3540 - val_loss: 0.3562\n",
            "Epoch 112/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3548 - val_loss: 0.3550\n",
            "Epoch 113/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3771 - val_loss: 0.3464\n",
            "Epoch 114/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3487 - val_loss: 0.3682\n",
            "Epoch 115/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3567 - val_loss: 0.3460\n",
            "Epoch 116/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3556 - val_loss: 0.3457\n",
            "Epoch 117/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3764 - val_loss: 0.3474\n",
            "Epoch 118/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3618 - val_loss: 0.3480\n",
            "Epoch 119/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3619 - val_loss: 0.3585\n",
            "Epoch 120/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3553 - val_loss: 0.3577\n",
            "Epoch 121/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3532 - val_loss: 0.3383\n",
            "Epoch 122/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3622 - val_loss: 0.3522\n",
            "Epoch 123/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3793 - val_loss: 0.3353\n",
            "Epoch 124/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3628 - val_loss: 0.3430\n",
            "Epoch 125/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3553 - val_loss: 0.3363\n",
            "Epoch 126/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3678 - val_loss: 0.3427\n",
            "Epoch 127/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3493 - val_loss: 0.3412\n",
            "Epoch 128/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3477 - val_loss: 0.3400\n",
            "Epoch 129/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3589 - val_loss: 0.3570\n",
            "Epoch 130/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3578 - val_loss: 0.3370\n",
            "Epoch 131/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3470 - val_loss: 0.3427\n",
            "Epoch 132/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3592 - val_loss: 0.3413\n",
            "Epoch 133/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3604 - val_loss: 0.3375\n",
            "Epoch 134/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3613 - val_loss: 0.3384\n",
            "Epoch 135/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3408 - val_loss: 0.3321\n",
            "Epoch 136/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3369 - val_loss: 0.3389\n",
            "Epoch 137/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3357 - val_loss: 0.3398\n",
            "Epoch 138/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3384 - val_loss: 0.3335\n",
            "Epoch 139/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3568 - val_loss: 0.3439\n",
            "Epoch 140/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3582 - val_loss: 0.3431\n",
            "Epoch 141/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3504 - val_loss: 0.3259\n",
            "Epoch 142/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3561 - val_loss: 0.3343\n",
            "Epoch 143/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3536 - val_loss: 0.3230\n",
            "Epoch 144/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3671 - val_loss: 0.3395\n",
            "Epoch 145/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3470 - val_loss: 0.3335\n",
            "Epoch 146/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3437 - val_loss: 0.3411\n",
            "Epoch 147/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3557 - val_loss: 0.3332\n",
            "Epoch 148/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3561 - val_loss: 0.3420\n",
            "Epoch 149/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3599 - val_loss: 0.3300\n",
            "Epoch 150/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3550 - val_loss: 0.3423\n",
            "Epoch 151/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3399 - val_loss: 0.3232\n",
            "Epoch 152/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3609 - val_loss: 0.3359\n",
            "Epoch 153/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3430 - val_loss: 0.3304\n",
            "Epoch 154/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3598 - val_loss: 0.3303\n",
            "Epoch 155/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3672 - val_loss: 0.3340\n",
            "Epoch 156/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3441 - val_loss: 0.3308\n",
            "Epoch 157/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3550 - val_loss: 0.3375\n",
            "Epoch 158/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3680 - val_loss: 0.3381\n",
            "Epoch 159/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3497 - val_loss: 0.3400\n",
            "Epoch 160/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3531 - val_loss: 0.3365\n",
            "Epoch 161/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3359 - val_loss: 0.3270\n",
            "Epoch 162/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3397 - val_loss: 0.3222\n",
            "Epoch 163/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3452 - val_loss: 0.3413\n",
            "Epoch 164/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3761 - val_loss: 0.3509\n",
            "Epoch 165/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3564 - val_loss: 0.3215\n",
            "Epoch 166/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3499 - val_loss: 0.3432\n",
            "Epoch 167/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3414 - val_loss: 0.3482\n",
            "Epoch 168/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3396 - val_loss: 0.3318\n",
            "Epoch 169/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3445 - val_loss: 0.3334\n",
            "Epoch 170/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3388 - val_loss: 0.3338\n",
            "Epoch 171/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3525 - val_loss: 0.3331\n",
            "Epoch 172/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3542 - val_loss: 0.3300\n",
            "Epoch 173/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3273 - val_loss: 0.3312\n",
            "Epoch 174/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3397 - val_loss: 0.3375\n",
            "Epoch 175/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3381 - val_loss: 0.3381\n",
            "Epoch 176/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3497 - val_loss: 0.3352\n",
            "Epoch 177/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3368 - val_loss: 0.3304\n",
            "Epoch 178/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3515 - val_loss: 0.3424\n",
            "Epoch 179/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3416 - val_loss: 0.3235\n",
            "Epoch 180/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3415 - val_loss: 0.3218\n",
            "Epoch 181/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3419 - val_loss: 0.3253\n",
            "Epoch 182/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3276 - val_loss: 0.3196\n",
            "Epoch 183/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3419 - val_loss: 0.3279\n",
            "Epoch 184/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3332 - val_loss: 0.3232\n",
            "Epoch 185/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3435 - val_loss: 0.3223\n",
            "Epoch 186/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3384 - val_loss: 0.3327\n",
            "Epoch 187/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3448 - val_loss: 0.3318\n",
            "Epoch 188/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3239 - val_loss: 0.3173\n",
            "Epoch 189/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3493 - val_loss: 0.3186\n",
            "Epoch 190/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3347 - val_loss: 0.3175\n",
            "Epoch 191/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3260 - val_loss: 0.3208\n",
            "Epoch 192/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3258 - val_loss: 0.3291\n",
            "Epoch 193/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3645 - val_loss: 0.3443\n",
            "Epoch 194/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3420 - val_loss: 0.3281\n",
            "Epoch 195/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3361 - val_loss: 0.3345\n",
            "Epoch 196/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3468 - val_loss: 0.3227\n",
            "Epoch 197/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3311 - val_loss: 0.3321\n",
            "Epoch 198/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3188 - val_loss: 0.3144\n",
            "Epoch 199/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3339 - val_loss: 0.3360\n",
            "Epoch 200/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3356 - val_loss: 0.3411\n",
            "Epoch 201/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3415 - val_loss: 0.3221\n",
            "Epoch 202/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3385 - val_loss: 0.3414\n",
            "Epoch 203/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3478 - val_loss: 0.3245\n",
            "Epoch 204/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3425 - val_loss: 0.3214\n",
            "Epoch 205/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3223 - val_loss: 0.3343\n",
            "Epoch 206/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3286 - val_loss: 0.3235\n",
            "Epoch 207/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3460 - val_loss: 0.3241\n",
            "Epoch 208/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3339 - val_loss: 0.3158\n",
            "Epoch 209/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3418 - val_loss: 0.3345\n",
            "Epoch 210/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3364 - val_loss: 0.3271\n",
            "Epoch 211/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3398 - val_loss: 0.3286\n",
            "Epoch 212/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3423 - val_loss: 0.3390\n",
            "Epoch 213/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3364 - val_loss: 0.3364\n",
            "Epoch 214/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3363 - val_loss: 0.3418\n",
            "Epoch 215/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3384 - val_loss: 0.3201\n",
            "Epoch 216/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3363 - val_loss: 0.3130\n",
            "Epoch 217/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3337 - val_loss: 0.3236\n",
            "Epoch 218/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3313 - val_loss: 0.3270\n",
            "Epoch 219/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3309 - val_loss: 0.3324\n",
            "Epoch 220/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3354 - val_loss: 0.3271\n",
            "Epoch 221/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3251 - val_loss: 0.3343\n",
            "Epoch 222/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3372 - val_loss: 0.3107\n",
            "Epoch 223/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3405 - val_loss: 0.3199\n",
            "Epoch 224/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3510 - val_loss: 0.3288\n",
            "Epoch 225/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3439 - val_loss: 0.3368\n",
            "Epoch 226/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3366 - val_loss: 0.3295\n",
            "Epoch 227/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3316 - val_loss: 0.3281\n",
            "Epoch 228/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3406 - val_loss: 0.3400\n",
            "Epoch 229/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3479 - val_loss: 0.3177\n",
            "Epoch 230/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3338 - val_loss: 0.3360\n",
            "Epoch 231/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3184 - val_loss: 0.3256\n",
            "Epoch 232/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3371 - val_loss: 0.3192\n",
            "Epoch 233/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3228 - val_loss: 0.3102\n",
            "Epoch 234/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3362 - val_loss: 0.3278\n",
            "Epoch 235/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3435 - val_loss: 0.3294\n",
            "Epoch 236/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3472 - val_loss: 0.3241\n",
            "Epoch 237/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3277 - val_loss: 0.3226\n",
            "Epoch 238/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3291 - val_loss: 0.3288\n",
            "Epoch 239/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3338 - val_loss: 0.3180\n",
            "Epoch 240/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3285 - val_loss: 0.3118\n",
            "Epoch 241/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3578 - val_loss: 0.3209\n",
            "Epoch 242/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3458 - val_loss: 0.3244\n",
            "Epoch 243/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3388 - val_loss: 0.3348\n",
            "Epoch 244/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3280 - val_loss: 0.3172\n",
            "Epoch 245/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3297 - val_loss: 0.3258\n",
            "Epoch 246/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3229 - val_loss: 0.3164\n",
            "Epoch 247/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3244 - val_loss: 0.3226\n",
            "Epoch 248/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3240 - val_loss: 0.3200\n",
            "Epoch 249/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3284 - val_loss: 0.3308\n",
            "Epoch 250/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3168 - val_loss: 0.3280\n",
            "Epoch 251/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3281 - val_loss: 0.3136\n",
            "Epoch 252/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3267 - val_loss: 0.3148\n",
            "Epoch 253/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3259 - val_loss: 0.3199\n",
            "Epoch 254/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3324 - val_loss: 0.3041\n",
            "Epoch 255/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3368 - val_loss: 0.3371\n",
            "Epoch 256/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3365 - val_loss: 0.3178\n",
            "Epoch 257/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3478 - val_loss: 0.3333\n",
            "Epoch 258/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3341 - val_loss: 0.3176\n",
            "Epoch 259/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3406 - val_loss: 0.3148\n",
            "Epoch 260/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3239 - val_loss: 0.3027\n",
            "Epoch 261/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3228 - val_loss: 0.3184\n",
            "Epoch 262/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3360 - val_loss: 0.3151\n",
            "Epoch 263/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3237 - val_loss: 0.3215\n",
            "Epoch 264/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3348 - val_loss: 0.3181\n",
            "Epoch 265/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3245 - val_loss: 0.3151\n",
            "Epoch 266/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3395 - val_loss: 0.3301\n",
            "Epoch 267/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3211 - val_loss: 0.3232\n",
            "Epoch 268/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3395 - val_loss: 0.2945\n",
            "Epoch 269/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3307 - val_loss: 0.3128\n",
            "Epoch 270/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3066 - val_loss: 0.3152\n",
            "Epoch 271/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3199 - val_loss: 0.3281\n",
            "Epoch 272/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3332 - val_loss: 0.3175\n",
            "Epoch 273/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3331 - val_loss: 0.3182\n",
            "Epoch 274/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3239 - val_loss: 0.3130\n",
            "Epoch 275/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3303 - val_loss: 0.3266\n",
            "Epoch 276/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3352 - val_loss: 0.2942\n",
            "Epoch 277/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3387 - val_loss: 0.3184\n",
            "Epoch 278/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3296 - val_loss: 0.3202\n",
            "Epoch 279/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3093 - val_loss: 0.3214\n",
            "Epoch 280/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3193 - val_loss: 0.3229\n",
            "Epoch 281/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3356 - val_loss: 0.3165\n",
            "Epoch 282/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3351 - val_loss: 0.3093\n",
            "Epoch 283/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3303 - val_loss: 0.3089\n",
            "Epoch 284/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.3101\n",
            "Epoch 285/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3131 - val_loss: 0.3217\n",
            "Epoch 286/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3188 - val_loss: 0.3118\n",
            "Epoch 287/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3259 - val_loss: 0.3207\n",
            "Epoch 288/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3292 - val_loss: 0.3141\n",
            "Epoch 289/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3482 - val_loss: 0.3125\n",
            "Epoch 290/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3354 - val_loss: 0.3155\n",
            "Epoch 291/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3212 - val_loss: 0.3163\n",
            "Epoch 292/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3281 - val_loss: 0.3184\n",
            "Epoch 293/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3213 - val_loss: 0.3110\n",
            "Epoch 294/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3199 - val_loss: 0.3149\n",
            "Epoch 295/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3129 - val_loss: 0.3149\n",
            "Epoch 296/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3366 - val_loss: 0.2952\n",
            "Epoch 297/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3312 - val_loss: 0.3145\n",
            "Epoch 298/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3393 - val_loss: 0.3056\n",
            "Epoch 299/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3275 - val_loss: 0.2958\n",
            "Epoch 300/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3061 - val_loss: 0.3027\n",
            "Epoch 301/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3248 - val_loss: 0.3022\n",
            "Epoch 302/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3271 - val_loss: 0.3100\n",
            "Epoch 303/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3310 - val_loss: 0.3051\n",
            "Epoch 304/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3305 - val_loss: 0.3069\n",
            "Epoch 305/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3238 - val_loss: 0.3192\n",
            "Epoch 306/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3296 - val_loss: 0.3169\n",
            "Epoch 307/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3372 - val_loss: 0.3219\n",
            "Epoch 308/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3386 - val_loss: 0.3213\n",
            "Epoch 309/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3323 - val_loss: 0.3088\n",
            "Epoch 310/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3305 - val_loss: 0.3121\n",
            "Epoch 311/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3231 - val_loss: 0.3017\n",
            "Epoch 312/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3421 - val_loss: 0.3370\n",
            "Epoch 313/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3430 - val_loss: 0.3191\n",
            "Epoch 314/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3175 - val_loss: 0.3159\n",
            "Epoch 315/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3328 - val_loss: 0.3040\n",
            "Epoch 316/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3357 - val_loss: 0.3163\n",
            "Epoch 317/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3313 - val_loss: 0.3180\n",
            "Epoch 318/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3039 - val_loss: 0.3076\n",
            "Epoch 319/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3395 - val_loss: 0.3153\n",
            "Epoch 320/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3211 - val_loss: 0.3131\n",
            "Epoch 321/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3220 - val_loss: 0.3116\n",
            "Epoch 322/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3290 - val_loss: 0.3107\n",
            "Epoch 323/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3310 - val_loss: 0.3200\n",
            "Epoch 324/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3307 - val_loss: 0.3164\n",
            "Epoch 325/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3164 - val_loss: 0.3093\n",
            "Epoch 326/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3237 - val_loss: 0.3227\n",
            "Epoch 326: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f860795d590>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ],
      "metadata": {
        "id": "eQexmEtauCVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "JbsEnToWudc0",
        "outputId": "efa30f60-377b-4c05-8414-e661fa22ffb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f860772cb10>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype('int32')"
      ],
      "metadata": {
        "id": "yUmrfKE3ul9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "gG7qRvjzvqzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G690YWi3vsrU",
        "outputId": "303e6a24-6ebb-4ce5-a429-cf0baaf51e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.97      0.88       325\n",
            "           1       0.96      0.77      0.85       323\n",
            "\n",
            "    accuracy                           0.87       648\n",
            "   macro avg       0.88      0.87      0.87       648\n",
            "weighted avg       0.88      0.87      0.87       648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(6,activation='relu'))\n",
        "\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(6,activation='relu'))\n",
        "\n",
        "\n",
        "\n",
        "# BINARY CLASSIFICATION\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "GJlPSYVfvui4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=X_train,y=y_train,epochs=2000,validation_data=(X_test,y_test),callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSBD03Uncbp5",
        "outputId": "6ba54a1c-901c-4813-a6cc-6e3f552a4c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "48/48 [==============================] - 2s 10ms/step - loss: 0.6998 - val_loss: 0.6904\n",
            "Epoch 2/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6874 - val_loss: 0.6799\n",
            "Epoch 3/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.6772 - val_loss: 0.6620\n",
            "Epoch 4/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6653 - val_loss: 0.6369\n",
            "Epoch 5/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6522 - val_loss: 0.6158\n",
            "Epoch 6/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6305 - val_loss: 0.5866\n",
            "Epoch 7/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6268 - val_loss: 0.5737\n",
            "Epoch 8/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.6089 - val_loss: 0.5585\n",
            "Epoch 9/2000\n",
            "48/48 [==============================] - 0s 5ms/step - loss: 0.5890 - val_loss: 0.5415\n",
            "Epoch 10/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5723 - val_loss: 0.5320\n",
            "Epoch 11/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5802 - val_loss: 0.5347\n",
            "Epoch 12/2000\n",
            "48/48 [==============================] - 0s 9ms/step - loss: 0.5650 - val_loss: 0.5174\n",
            "Epoch 13/2000\n",
            "48/48 [==============================] - 0s 7ms/step - loss: 0.5670 - val_loss: 0.5123\n",
            "Epoch 14/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5539 - val_loss: 0.5000\n",
            "Epoch 15/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5349 - val_loss: 0.4926\n",
            "Epoch 16/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.5316 - val_loss: 0.4793\n",
            "Epoch 17/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.5167 - val_loss: 0.4663\n",
            "Epoch 18/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.5052 - val_loss: 0.4457\n",
            "Epoch 19/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4910 - val_loss: 0.4309\n",
            "Epoch 20/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4965 - val_loss: 0.4308\n",
            "Epoch 21/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4999 - val_loss: 0.4326\n",
            "Epoch 22/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4747 - val_loss: 0.4167\n",
            "Epoch 23/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4576 - val_loss: 0.4157\n",
            "Epoch 24/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4511 - val_loss: 0.4024\n",
            "Epoch 25/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4494 - val_loss: 0.4031\n",
            "Epoch 26/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4534 - val_loss: 0.3921\n",
            "Epoch 27/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4309 - val_loss: 0.3889\n",
            "Epoch 28/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4305 - val_loss: 0.3810\n",
            "Epoch 29/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4214 - val_loss: 0.3723\n",
            "Epoch 30/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4224 - val_loss: 0.3743\n",
            "Epoch 31/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4350 - val_loss: 0.3660\n",
            "Epoch 32/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4124 - val_loss: 0.3623\n",
            "Epoch 33/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4080 - val_loss: 0.3604\n",
            "Epoch 34/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4141 - val_loss: 0.3604\n",
            "Epoch 35/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4092 - val_loss: 0.3504\n",
            "Epoch 36/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3830 - val_loss: 0.3430\n",
            "Epoch 37/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.4054 - val_loss: 0.3459\n",
            "Epoch 38/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3901 - val_loss: 0.3623\n",
            "Epoch 39/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3985 - val_loss: 0.3442\n",
            "Epoch 40/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3901 - val_loss: 0.3477\n",
            "Epoch 41/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3869 - val_loss: 0.3338\n",
            "Epoch 42/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3940 - val_loss: 0.3370\n",
            "Epoch 43/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3948 - val_loss: 0.3292\n",
            "Epoch 44/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3815 - val_loss: 0.3360\n",
            "Epoch 45/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3773 - val_loss: 0.3335\n",
            "Epoch 46/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3806 - val_loss: 0.3311\n",
            "Epoch 47/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3801 - val_loss: 0.3238\n",
            "Epoch 48/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3659 - val_loss: 0.3203\n",
            "Epoch 49/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3523 - val_loss: 0.3126\n",
            "Epoch 50/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3701 - val_loss: 0.3102\n",
            "Epoch 51/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3755 - val_loss: 0.3246\n",
            "Epoch 52/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.3213\n",
            "Epoch 53/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3580 - val_loss: 0.3184\n",
            "Epoch 54/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3460 - val_loss: 0.3059\n",
            "Epoch 55/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3621 - val_loss: 0.3268\n",
            "Epoch 56/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3727 - val_loss: 0.3076\n",
            "Epoch 57/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3728 - val_loss: 0.3154\n",
            "Epoch 58/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3527 - val_loss: 0.3029\n",
            "Epoch 59/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3390 - val_loss: 0.3068\n",
            "Epoch 60/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3641 - val_loss: 0.3056\n",
            "Epoch 61/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3396 - val_loss: 0.2990\n",
            "Epoch 62/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3328 - val_loss: 0.2970\n",
            "Epoch 63/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3472 - val_loss: 0.3078\n",
            "Epoch 64/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3415 - val_loss: 0.2978\n",
            "Epoch 65/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3449 - val_loss: 0.2946\n",
            "Epoch 66/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3536 - val_loss: 0.3050\n",
            "Epoch 67/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3413 - val_loss: 0.2869\n",
            "Epoch 68/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3402 - val_loss: 0.2881\n",
            "Epoch 69/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3444 - val_loss: 0.3116\n",
            "Epoch 70/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3435 - val_loss: 0.2941\n",
            "Epoch 71/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3412 - val_loss: 0.2909\n",
            "Epoch 72/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3422 - val_loss: 0.3056\n",
            "Epoch 73/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3612 - val_loss: 0.2880\n",
            "Epoch 74/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3353 - val_loss: 0.2886\n",
            "Epoch 75/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3207 - val_loss: 0.2860\n",
            "Epoch 76/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3678 - val_loss: 0.2938\n",
            "Epoch 77/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3331 - val_loss: 0.2884\n",
            "Epoch 78/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3423 - val_loss: 0.2847\n",
            "Epoch 79/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3508 - val_loss: 0.2995\n",
            "Epoch 80/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3396 - val_loss: 0.2827\n",
            "Epoch 81/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3310 - val_loss: 0.2875\n",
            "Epoch 82/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3323 - val_loss: 0.2877\n",
            "Epoch 83/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3492 - val_loss: 0.2868\n",
            "Epoch 84/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3196 - val_loss: 0.2971\n",
            "Epoch 85/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3632 - val_loss: 0.2898\n",
            "Epoch 86/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3319 - val_loss: 0.2814\n",
            "Epoch 87/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3534 - val_loss: 0.2884\n",
            "Epoch 88/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3238 - val_loss: 0.2800\n",
            "Epoch 89/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3202 - val_loss: 0.2800\n",
            "Epoch 90/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3211 - val_loss: 0.2784\n",
            "Epoch 91/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3345 - val_loss: 0.2791\n",
            "Epoch 92/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3324 - val_loss: 0.2818\n",
            "Epoch 93/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3228 - val_loss: 0.2721\n",
            "Epoch 94/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3415 - val_loss: 0.2801\n",
            "Epoch 95/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3231 - val_loss: 0.2792\n",
            "Epoch 96/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3408 - val_loss: 0.2754\n",
            "Epoch 97/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3144 - val_loss: 0.2863\n",
            "Epoch 98/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3110 - val_loss: 0.2773\n",
            "Epoch 99/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3289 - val_loss: 0.2768\n",
            "Epoch 100/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3250 - val_loss: 0.2724\n",
            "Epoch 101/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3225 - val_loss: 0.2785\n",
            "Epoch 102/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3241 - val_loss: 0.2663\n",
            "Epoch 103/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3253 - val_loss: 0.2672\n",
            "Epoch 104/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3227 - val_loss: 0.2685\n",
            "Epoch 105/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3330 - val_loss: 0.2801\n",
            "Epoch 106/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3191 - val_loss: 0.2734\n",
            "Epoch 107/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3101 - val_loss: 0.2699\n",
            "Epoch 108/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3100 - val_loss: 0.2908\n",
            "Epoch 109/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2910 - val_loss: 0.2671\n",
            "Epoch 110/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3264 - val_loss: 0.2677\n",
            "Epoch 111/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3295 - val_loss: 0.2980\n",
            "Epoch 112/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3228 - val_loss: 0.2772\n",
            "Epoch 113/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3285 - val_loss: 0.2695\n",
            "Epoch 114/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3196 - val_loss: 0.2731\n",
            "Epoch 115/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3109 - val_loss: 0.3296\n",
            "Epoch 116/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3416 - val_loss: 0.2691\n",
            "Epoch 117/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3242 - val_loss: 0.2809\n",
            "Epoch 118/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3218 - val_loss: 0.2766\n",
            "Epoch 119/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3184 - val_loss: 0.2769\n",
            "Epoch 120/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3091 - val_loss: 0.2675\n",
            "Epoch 121/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3145 - val_loss: 0.2977\n",
            "Epoch 122/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3230 - val_loss: 0.2664\n",
            "Epoch 123/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3146 - val_loss: 0.2661\n",
            "Epoch 124/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2963 - val_loss: 0.2730\n",
            "Epoch 125/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3306 - val_loss: 0.2804\n",
            "Epoch 126/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3040 - val_loss: 0.2588\n",
            "Epoch 127/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3199 - val_loss: 0.2645\n",
            "Epoch 128/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3127 - val_loss: 0.2639\n",
            "Epoch 129/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3156 - val_loss: 0.2602\n",
            "Epoch 130/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3201 - val_loss: 0.2695\n",
            "Epoch 131/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3292 - val_loss: 0.2697\n",
            "Epoch 132/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3041 - val_loss: 0.2592\n",
            "Epoch 133/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2995 - val_loss: 0.2589\n",
            "Epoch 134/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3116 - val_loss: 0.2504\n",
            "Epoch 135/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3081 - val_loss: 0.2496\n",
            "Epoch 136/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3170 - val_loss: 0.2486\n",
            "Epoch 137/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2957 - val_loss: 0.2463\n",
            "Epoch 138/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3084 - val_loss: 0.2553\n",
            "Epoch 139/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.3063 - val_loss: 0.2471\n",
            "Epoch 140/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3158 - val_loss: 0.2553\n",
            "Epoch 141/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2995 - val_loss: 0.2596\n",
            "Epoch 142/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3058 - val_loss: 0.2528\n",
            "Epoch 143/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3103 - val_loss: 0.2524\n",
            "Epoch 144/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2887 - val_loss: 0.2510\n",
            "Epoch 145/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3088 - val_loss: 0.2540\n",
            "Epoch 146/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2956 - val_loss: 0.2520\n",
            "Epoch 147/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3121 - val_loss: 0.2473\n",
            "Epoch 148/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3365 - val_loss: 0.2590\n",
            "Epoch 149/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2994 - val_loss: 0.2561\n",
            "Epoch 150/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.2501\n",
            "Epoch 151/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2917 - val_loss: 0.2490\n",
            "Epoch 152/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3031 - val_loss: 0.2539\n",
            "Epoch 153/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3198 - val_loss: 0.2547\n",
            "Epoch 154/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2950 - val_loss: 0.2455\n",
            "Epoch 155/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2772 - val_loss: 0.2587\n",
            "Epoch 156/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3115 - val_loss: 0.2537\n",
            "Epoch 157/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2992 - val_loss: 0.2546\n",
            "Epoch 158/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2926 - val_loss: 0.2471\n",
            "Epoch 159/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3143 - val_loss: 0.2546\n",
            "Epoch 160/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2973 - val_loss: 0.2587\n",
            "Epoch 161/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3078 - val_loss: 0.2523\n",
            "Epoch 162/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3189 - val_loss: 0.2575\n",
            "Epoch 163/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2990 - val_loss: 0.2701\n",
            "Epoch 164/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2915 - val_loss: 0.2429\n",
            "Epoch 165/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.2502\n",
            "Epoch 166/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3021 - val_loss: 0.2502\n",
            "Epoch 167/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3208 - val_loss: 0.2536\n",
            "Epoch 168/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2825 - val_loss: 0.2489\n",
            "Epoch 169/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2927 - val_loss: 0.2539\n",
            "Epoch 170/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2868 - val_loss: 0.2552\n",
            "Epoch 171/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2999 - val_loss: 0.2642\n",
            "Epoch 172/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3040 - val_loss: 0.2573\n",
            "Epoch 173/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3041 - val_loss: 0.2576\n",
            "Epoch 174/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2801 - val_loss: 0.2527\n",
            "Epoch 175/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3073 - val_loss: 0.2423\n",
            "Epoch 176/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2840 - val_loss: 0.2332\n",
            "Epoch 177/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3099 - val_loss: 0.2409\n",
            "Epoch 178/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2875 - val_loss: 0.2433\n",
            "Epoch 179/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3075 - val_loss: 0.2410\n",
            "Epoch 180/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2997 - val_loss: 0.2764\n",
            "Epoch 181/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.2510\n",
            "Epoch 182/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2891 - val_loss: 0.2426\n",
            "Epoch 183/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2808 - val_loss: 0.2466\n",
            "Epoch 184/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.2462\n",
            "Epoch 185/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2956 - val_loss: 0.2464\n",
            "Epoch 186/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2940 - val_loss: 0.2450\n",
            "Epoch 187/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2903 - val_loss: 0.2536\n",
            "Epoch 188/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2858 - val_loss: 0.2570\n",
            "Epoch 189/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2863 - val_loss: 0.2317\n",
            "Epoch 190/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2990 - val_loss: 0.2293\n",
            "Epoch 191/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2995 - val_loss: 0.2490\n",
            "Epoch 192/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3054 - val_loss: 0.2667\n",
            "Epoch 193/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3081 - val_loss: 0.2704\n",
            "Epoch 194/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2916 - val_loss: 0.2529\n",
            "Epoch 195/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2871 - val_loss: 0.2415\n",
            "Epoch 196/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2880 - val_loss: 0.2731\n",
            "Epoch 197/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2909 - val_loss: 0.2387\n",
            "Epoch 198/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2953 - val_loss: 0.2517\n",
            "Epoch 199/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3109 - val_loss: 0.2574\n",
            "Epoch 200/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2940 - val_loss: 0.2486\n",
            "Epoch 201/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2894 - val_loss: 0.2537\n",
            "Epoch 202/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2952 - val_loss: 0.2497\n",
            "Epoch 203/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2960 - val_loss: 0.2670\n",
            "Epoch 204/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3020 - val_loss: 0.2503\n",
            "Epoch 205/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2941 - val_loss: 0.2502\n",
            "Epoch 206/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3017 - val_loss: 0.2512\n",
            "Epoch 207/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2951 - val_loss: 0.2407\n",
            "Epoch 208/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2943 - val_loss: 0.2379\n",
            "Epoch 209/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2942 - val_loss: 0.2318\n",
            "Epoch 210/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2918 - val_loss: 0.2454\n",
            "Epoch 211/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2878 - val_loss: 0.2378\n",
            "Epoch 212/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2980 - val_loss: 0.2537\n",
            "Epoch 213/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2720 - val_loss: 0.2427\n",
            "Epoch 214/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2801 - val_loss: 0.2464\n",
            "Epoch 215/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2920 - val_loss: 0.2391\n",
            "Epoch 216/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2770 - val_loss: 0.2437\n",
            "Epoch 217/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2924 - val_loss: 0.2312\n",
            "Epoch 218/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2955 - val_loss: 0.2696\n",
            "Epoch 219/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3153 - val_loss: 0.2475\n",
            "Epoch 220/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2710 - val_loss: 0.2370\n",
            "Epoch 221/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3088 - val_loss: 0.2432\n",
            "Epoch 222/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3059 - val_loss: 0.2388\n",
            "Epoch 223/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2781 - val_loss: 0.2265\n",
            "Epoch 224/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2674 - val_loss: 0.2344\n",
            "Epoch 225/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2864 - val_loss: 0.2412\n",
            "Epoch 226/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2992 - val_loss: 0.2280\n",
            "Epoch 227/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2899 - val_loss: 0.2327\n",
            "Epoch 228/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2960 - val_loss: 0.2415\n",
            "Epoch 229/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2904 - val_loss: 0.2332\n",
            "Epoch 230/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2939 - val_loss: 0.2349\n",
            "Epoch 231/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3194 - val_loss: 0.2762\n",
            "Epoch 232/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2959 - val_loss: 0.2379\n",
            "Epoch 233/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2673 - val_loss: 0.2218\n",
            "Epoch 234/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2870 - val_loss: 0.2441\n",
            "Epoch 235/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2803 - val_loss: 0.2452\n",
            "Epoch 236/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2875 - val_loss: 0.2286\n",
            "Epoch 237/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2829 - val_loss: 0.2312\n",
            "Epoch 238/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2702 - val_loss: 0.2497\n",
            "Epoch 239/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2998 - val_loss: 0.3113\n",
            "Epoch 240/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2824 - val_loss: 0.2468\n",
            "Epoch 241/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3045 - val_loss: 0.2376\n",
            "Epoch 242/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3054 - val_loss: 0.2330\n",
            "Epoch 243/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2940 - val_loss: 0.2375\n",
            "Epoch 244/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2917 - val_loss: 0.2436\n",
            "Epoch 245/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2835 - val_loss: 0.2611\n",
            "Epoch 246/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2971 - val_loss: 0.2293\n",
            "Epoch 247/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2648 - val_loss: 0.2536\n",
            "Epoch 248/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3011 - val_loss: 0.2328\n",
            "Epoch 249/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2961 - val_loss: 0.2289\n",
            "Epoch 250/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2777 - val_loss: 0.2452\n",
            "Epoch 251/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2835 - val_loss: 0.2451\n",
            "Epoch 252/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2894 - val_loss: 0.2555\n",
            "Epoch 253/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2869 - val_loss: 0.2434\n",
            "Epoch 254/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2746 - val_loss: 0.2409\n",
            "Epoch 255/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2737 - val_loss: 0.2302\n",
            "Epoch 256/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2772 - val_loss: 0.2300\n",
            "Epoch 257/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2870 - val_loss: 0.2332\n",
            "Epoch 258/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2801 - val_loss: 0.2410\n",
            "Epoch 259/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2797 - val_loss: 0.2466\n",
            "Epoch 260/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2958 - val_loss: 0.2301\n",
            "Epoch 261/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2870 - val_loss: 0.2316\n",
            "Epoch 262/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2782 - val_loss: 0.2333\n",
            "Epoch 263/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2800 - val_loss: 0.2284\n",
            "Epoch 264/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2838 - val_loss: 0.2430\n",
            "Epoch 265/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2847 - val_loss: 0.2323\n",
            "Epoch 266/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.3075 - val_loss: 0.2398\n",
            "Epoch 267/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2703 - val_loss: 0.2279\n",
            "Epoch 268/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2828 - val_loss: 0.2392\n",
            "Epoch 269/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2918 - val_loss: 0.2412\n",
            "Epoch 270/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2816 - val_loss: 0.2292\n",
            "Epoch 271/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2718 - val_loss: 0.2258\n",
            "Epoch 272/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2816 - val_loss: 0.2191\n",
            "Epoch 273/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2974 - val_loss: 0.2261\n",
            "Epoch 274/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2766 - val_loss: 0.2232\n",
            "Epoch 275/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2898 - val_loss: 0.2580\n",
            "Epoch 276/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2888 - val_loss: 0.2315\n",
            "Epoch 277/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2551 - val_loss: 0.2523\n",
            "Epoch 278/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2833 - val_loss: 0.2311\n",
            "Epoch 279/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2808 - val_loss: 0.2424\n",
            "Epoch 280/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2907 - val_loss: 0.2227\n",
            "Epoch 281/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2865 - val_loss: 0.2413\n",
            "Epoch 282/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3023 - val_loss: 0.2280\n",
            "Epoch 283/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2895 - val_loss: 0.2246\n",
            "Epoch 284/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2555 - val_loss: 0.2235\n",
            "Epoch 285/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2960 - val_loss: 0.2459\n",
            "Epoch 286/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2563 - val_loss: 0.2338\n",
            "Epoch 287/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2640 - val_loss: 0.2267\n",
            "Epoch 288/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2719 - val_loss: 0.2214\n",
            "Epoch 289/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2642 - val_loss: 0.2204\n",
            "Epoch 290/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2868 - val_loss: 0.2241\n",
            "Epoch 291/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2734 - val_loss: 0.2243\n",
            "Epoch 292/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2742 - val_loss: 0.2307\n",
            "Epoch 293/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2753 - val_loss: 0.2239\n",
            "Epoch 294/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2772 - val_loss: 0.2261\n",
            "Epoch 295/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2685 - val_loss: 0.2257\n",
            "Epoch 296/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2809 - val_loss: 0.2227\n",
            "Epoch 297/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2750 - val_loss: 0.2191\n",
            "Epoch 298/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2851 - val_loss: 0.2464\n",
            "Epoch 299/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2748 - val_loss: 0.2631\n",
            "Epoch 300/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2741 - val_loss: 0.2241\n",
            "Epoch 301/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2704 - val_loss: 0.2255\n",
            "Epoch 302/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2810 - val_loss: 0.2279\n",
            "Epoch 303/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2726 - val_loss: 0.2245\n",
            "Epoch 304/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2757 - val_loss: 0.2290\n",
            "Epoch 305/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2742 - val_loss: 0.2256\n",
            "Epoch 306/2000\n",
            "48/48 [==============================] - 0s 2ms/step - loss: 0.2657 - val_loss: 0.2202\n",
            "Epoch 307/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2657 - val_loss: 0.2195\n",
            "Epoch 308/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3058 - val_loss: 0.2482\n",
            "Epoch 309/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2801 - val_loss: 0.2466\n",
            "Epoch 310/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2783 - val_loss: 0.2245\n",
            "Epoch 311/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.3100 - val_loss: 0.2412\n",
            "Epoch 312/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2908 - val_loss: 0.2550\n",
            "Epoch 313/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2847 - val_loss: 0.2552\n",
            "Epoch 314/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2885 - val_loss: 0.2327\n",
            "Epoch 315/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2744 - val_loss: 0.2407\n",
            "Epoch 316/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2773 - val_loss: 0.2332\n",
            "Epoch 317/2000\n",
            "48/48 [==============================] - 0s 4ms/step - loss: 0.2708 - val_loss: 0.2318\n",
            "Epoch 318/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2809 - val_loss: 0.2280\n",
            "Epoch 319/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2654 - val_loss: 0.2267\n",
            "Epoch 320/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2881 - val_loss: 0.2304\n",
            "Epoch 321/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2596 - val_loss: 0.2263\n",
            "Epoch 322/2000\n",
            "48/48 [==============================] - 0s 3ms/step - loss: 0.2842 - val_loss: 0.2350\n",
            "Epoch 322: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7c92dbe550>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "losses.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8PVsjQRBcd8N",
        "outputId": "f42c5ca5-021d-4293-dff0-a2ff4a8b731b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7c92c199d0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype('int32')"
      ],
      "metadata": {
        "id": "b1jLPQjbdBEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R23BU89cptS",
        "outputId": "1b33683a-8cec-4729-de26-c62777b12532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.99      0.90       325\n",
            "           1       0.98      0.79      0.88       323\n",
            "\n",
            "    accuracy                           0.89       648\n",
            "   macro avg       0.91      0.89      0.89       648\n",
            "weighted avg       0.91      0.89      0.89       648\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test,predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVrE7RDQc7FI",
        "outputId": "81cec0cf-bf8c-424e-a860-774eac20eaa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[321   4]\n",
            " [ 67 256]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2JIJzOA_hXLz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}