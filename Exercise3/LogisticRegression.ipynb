{"cells":[{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\n\n# TODO: Upload the file \"Iris_modified6_5mod.csv\" to Databricks and load it here. \n#       Hint: Store the file location after uploading and chose the correct column separator\ndf = spark.read.csv(\"TODO\", header = \"true\", sep = \"TODO\", inferSchema=\"true\")\n\n# TODO: Print the first 5 lines of the data frame\n# Note: The first column is the label, the columns a0 and a1 are IDs, the remaining columns are features\n\n\n\n# TODO: Split into training and test data \ntraining, testing = TODO\n\n# Configure an ML pipeline, which consists of two stages: feature assembler and lr.\n# Transform n feature vectors into one single vector column\n# TODO: Select only those columns of the data set that are features\nassembler = VectorAssembler(inputCols=training.columns[TODO], outputCol='features')\n\n# TODO: us logistic regression with parameters maxIter=10, regParam=0.01\nlr = TODO\n\npipeline = Pipeline(stages=[assembler, lr])\n\n# TODO: print the parameters\n\n\n# predict \nmodel = pipeline.fit(training)\nprediction = model.transform(testing)\n\n# TODO: Select only the columns 'features, label, prediction' of DataFrame 'prediction'\nselected = TODO\n\n# TODO: Caculate and print prediction accuracy\n\n    "],"metadata":{},"outputs":[],"execution_count":1}],"metadata":{"name":"Logistic Regression Simple","notebookId":2395377288287685},"nbformat":4,"nbformat_minor":0}
